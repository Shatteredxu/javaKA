[TOC]



### 1.Jvm的垃圾回收机制

https://mp.weixin.qq.com/s/Cy9IdUZDwE3C4X4iUWnggA

1. 回收的对象： java堆和方法区

2. 找到需要回收的对象：引用计数法和可达性分析

3. 回收算法：标记-清除算法（效率都高，会产生大量不连续的内存碎片），复制算法（会浪费一半的内存空间），标记-整理算法（移动对象需要STW）,分代收集算法
4. 具体的收集器：新生代收集器，老年代收集器，
5. 比较重要的G1,CMS，ZGC

### 2.ping命令的工作过程及原理

https://blog.csdn.net/lcx390549721/article/details/82781483

ping工作在应用层，但不实用TCP协议，使用网络层的ICMP协议

ping 命令会发送一份ICMP回显请求报文给目标主机，并等待目标主机返回ICMP回显应答。因为ICMP协议会要求目标主机在收到消息之后，必须返回ICMP应答消息给源主机，如果源主机在一定时间内收到了目标主机的应答，则表明两台主机之间网络是可达的。

### 3.HTTPS报文有什么

可能是书上写了的

https://blog.csdn.net/scanf_linux/article/details/107614117

### 4.HTTP和HTTPS区别

1、https协议需要到CA申请证书。

2、http是超文本传输协议，采用明文传输信息，存在信息窃听、信息篡改和信息劫持的风险。https则是具有安全性的ssl/tls加密传输协议。而协议TLS/SSL具有身份验证、信息加密和完整性校验的功能，可以避免此类问题发生。

3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443；使用的URL也不一样，前者为http//:URL，后者为https//:URL。

4、http的连接很简单，是无状态的；HTTPS协议是由SSL/TLS+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

### 5.HashMap原理

https://itlemon.blog.csdn.net/article/details/104271481

### 6.session工作原理

https://blog.csdn.net/sinat_36184075/article/details/105674613

https://www.cnblogs.com/woshimrf/p/5317776.html

**Session生命周期结束时机：**

**浏览器关闭**：销毁Cookie中的jsessionid=xxx，原session对象会保留默认30min后才销毁，30分钟后为新的session;
	**session销毁**：主动调用 session.invalidate() 方法后，立即将session对象销毁，再次访问时会创建新的session.

### 7.Synchronized实现原理

https://blog.csdn.net/jinjiniao1/article/details/91546512

### 8.CurrentHashMap的实现原理



### 9.多线程下HashMap为什么会死循环

https://developer.aliyun.com/article/38431

### 10.缓存

1. 数据库数据缓存：memcached，Redis
2. 反向代理缓存，CDN缓存，DNS
3.  web应用层缓存
4. 浏览器端缓存



### 11.用户反应网站卡，问都有哪些可能性，以及排查方法。

先判断是server端问题还是client端出现问题，

> 检测工具：
>
> 浏览器调试，服务器资源使用情况，负载等情况，mysql日志



> 解决办法：
>
> 1. 加带宽
> 2. sql语句优化
> 3. 数据库分库分表或者读写分离
> 4. CDN缓存,静态页面缓存
> 5. 网站架构（添加服务器，负载均衡）

如果是server端，1. 服务器带宽不够2. 服务器负载过大3. 开发代码SQL代码需要优化 4. 数据库数据多，

>   可以先使用工具查找问题(GC,系统负载，CPU,内存等资源),
>
>   1.   首先就是linux系统情况，使用top命令查看负载，free，io等情况还有dstat命令，全能系统信息统计工具，阿里的 arthas 不错。淘宝也有一个 profiler。
>   2.   查看JVM的GC情况
>   3.   查看数据库
>   4.   Sql语句

### 12.java中的异常体系

https://blog.csdn.net/hguisu/article/details/6155636

1.   finally中的thorw,return会覆盖catch中的
2.   在try中执行到return语句时，不会真正的return，即只是会计算return中的表达式，之后将结果保存在一个临时栈中，接着执行finally中的语句，最后才会从临时栈中取出之前的结果返回。
3.   try里面return后，catch中的代码不会执行，但是finally会执行

### 15.缓存

1. 浏览器/APP缓存

2. CDN缓存

3. 接入层缓存

   > Nginx本地缓存
   >
   > PageSpeed
   >
   > Varnish

4. 应用层缓存

> 1. HashMap 或者 ConcurrentHashMap
> 2. 在 Java 中基于 LinkedHashMap 类，提供了一个自动清理最老元素的功能，，基于这个特质，可以将改造成一个LRU（Least Recently Used ，表示最近最少使用）缓存使用。
> 3. EhCache缓存：支持堆内缓存（占用JVM空间，引发频繁GC）和堆外缓存(堆外内存中的对象必须要序列化，键和值必须实现Serializable接口，因此存取速度上会比堆内缓存慢。在Java中可以通过 -XX:MaxDirectMemorySize 参数设置堆外内存的上限。)
> 4. 缓存数据存储在磁盘上，数据可以不丢失，更大的存储空间，缓存在磁盘上的数据也需要支持序列化，速度会被比内存更慢
> 5. Guava Cache 是其中的一个专门用于处理本地缓存的轻量级框架，是全内存方式的本地缓存，而且是线程安全的。和 ConcurrentMap 相比，Guava Cache 可以限制内存的占用，并可设置缓存的过期时间，可以自动回收数据，而 ConcurrentMap 只能通过静态方式来控制缓存，移除数据元素需要显示的方式来移除
> 6. Guava Cache四种内存回收方式
>
> 堆内缓存：
>
> 堆外缓存:

Guava Cache和EhCache的区别？

https://www.cnblogs.com/liushijie/p/5217981.html

5. 分布式缓存

缓存一致性问题怎么解决？

https://mp.weixin.qq.com/s/dYvM8_6SQnYRB6KjPsprbw

> 1. 先删除缓存，再更新数据库。解决方案是使用延迟双删。
> 2. 先更新数据库，再删除缓存。解决方案是消息队列或者其他binlog同步，引入消息队列会带来更多的问题，并不推荐直接使用。
> 3. 通过在总线加LOCK, 或者通过缓存一致性协议



### 16. 高可用解决方案

1. 降级
2. 限流

3. 切流量
4. 可回滚

### 20.java动态代理

JDK动态代理



Gglib动态代理

### 18.加密算法

对称加密：DES，3DES，AES

非对称加密：RSA,DSA,

散列加密：SHA-1,MD5



### 24 负载均衡算法有哪些？

负载均衡被设计用来处理大型网站的高并发问题，也就是根据需求将客户端的请求发送到不同的服务器进行处理

主要的负载均衡算法有：

1.轮询法：按顺序分配，而不管服务器端的总负载和当前负载。

2.随机法：根据随机函数，随机选择一台机器进行分配

3.源地址哈希法：根据服务消费者请求客户端的IP地址，通过哈希函数计算得到一个哈希值，将此哈希值和服务器列表的大小进行取模运算，得到的结果便是要访问的服务器地址的序号。采用源地址哈希法进行负载均衡，相同的IP客户端，如果服务器列表不变，将映射到同一个后台服务器进行访问。

4.加权轮询法：配置高、负载低的机器分配更高的权重，使其能处理更多的请求，而配置低、负载高的机器，则给其分配较低的权重，降低其系统负载，将请求按照顺序且根据权重分配给后端。

5.最小连接数法：

### 25 LRU算法

**用到缓存，基本都会有LRU**

##### 1.操作系统

由于操作系统的内存有限，在运行大型的程序的时候，不能把整个程序加载到内存中，所以根据局部性原理，操作系统引入虚拟内存，也就是先将程序多个页面，每次只需要将需要的页面加载进入内存，当程序需要的时候，通过页面置换算法，将内存腾出来，换上需要的，所以就有了页面置换算法，好的置换算法能够有效减少页面更换频率。

1. 最佳置换算法
2. 先进先出算法
3. 最近最久未使用算法：将最近长时间潍坊问的页面换掉，因为根据**局部性原理**
4. 时钟置换算法

##### 2.算法题

双向链表+hashMap，可以使用get和put时间复杂度都为O(1)

```java
class LRUCache {
    class DLinkedNode{
        int key;
        int value;
        DLinkedNode pre;
        DLinkedNode next;
        public DLinkedNode(){}
        public DLinkedNode(int _key,int _value){
            key = _key;
            value = _value;
        }
    }
    private Map<Integer,DLinkedNode> cache = new HashMap<>();
    private int size;
    private int capacity;
    private DLinkedNode head,tail;
    public LRUCache(int capacity) {
        this.size=0;
        this.capacity = capacity;
        head = new DLinkedNode();
        tail = new DLinkedNode();
        head.next = tail;
        tail.pre = head;
    }
    
    public int get(int key) {
        DLinkedNode node =  cache.get(key);
        if(node==null){
            return -1;
        }
        moveToHead(node);
        return node.value;
    }
    
    public void put(int key, int value) {
        DLinkedNode node = cache.get(key);
        if(node == null){
            DLinkedNode newNode = new DLinkedNode(key,value);
            cache.put(key,newNode);
            addToHead(newNode);
            ++size;
            if(size>capacity){
                DLinkedNode tail = removeTail();
                cache.remove(tail.key);
                --size;
            }
        }else{
            node.value = value;
            moveToHead(node);
        }
    }
    void addToHead(DLinkedNode node){
        node.pre = head;
        node.next = head.next;
        node.pre.next = node;
        node.next.pre = node;
    }
     void removeNode(DLinkedNode node) {
        node.pre.next = node.next;
        node.next.pre = node.pre;
    }
    void moveToHead(DLinkedNode node){
        removeNode(node);
        addToHead(node);
    }
    DLinkedNode removeTail(){
        DLinkedNode res = tail.pre;
        removeNode(res);
        return res;
    }
}
```



##### 3.Redis中的LRU

Redis 3.0中对于 LRU 替换算法的优化，在只维护一个eviction pool带来的少量开销情况下，对算法效率的提升是比较明显的，效率的提升带来的是访问命中率的提升。同时，在目前3.4的unstable版本中我们也可以看见Redis计划实现 LFU 算法以支持更丰富的业务场景，大致思想是**随机取出若干个key，然后按照访问时间排序后，淘汰掉最不经常使用**

*   `volatile-lru` 设置了过期时间的key参与近似的lru淘汰策略
*   `allkeys-lru` 所有的key均参与近似的lru淘汰策略

`https://zhuanlan.zhihu.com/p/34133067`

### 26 幂等性解决方案

1、select操作

2、删除操作

3、唯一索引

4、加锁

5、***保证消息的幂等性：***无论是生产端的幂等性保证方式，还是消费端通用的幂等性保证方式，它们的共同特点都是为每一个消息生成一个唯一的 ID，然后在使用这个消息的时候，先比对这个 ID 是否已经存在，如果存在，则认为消息已经被使用过。所以这种方式是一种标准的实现幂等的方式

### 27 关于object o = new Object();

##### 1.对象创建过程

##### 2.加问DCL要不要加volatile问题?(指令重排)

关于指令重排问题：https://www.bilibili.com/video/BV1Fv411J7n4?p=15

##### 3.对象在内存中的存储布局?(对象与数组的存储不同)

markword

class pointer

instace data

padding

##### 4.对象头具体包括什么?(markword klasspointer)synchronized锁信息

##### 5．对象怎么定位?(直接间接)

##### 6.对象怎么分配?(栈上-线程本地-Eden-old)

##### 7.object o = new Object()在内存中占用多少字节?

##### 8.新问题:为什么hotspot不使用c++对象来代表java对象?

##### 9．新问题:class对象是在堆还是在方法区?

### 28 内存屏障

#####  CPU内存屏障

2.sfence, 是一种Store Barrier 写屏障 
       3.mfence, 是一种全能型的屏障，具备ifence和sfence的能力

**写内存屏障(Store Memory Barrier)**: 在指令后插入Store Barrier, 能让写入缓存中的最新数据更新写入主内存, 让其他线程可见
强制写入主内存, 这种显示调用, CPU就不会因为性能考虑而进行指令重排

**读内存屏障(Load Memory Barrier)**: 在指令前插入Load Barrier, 可以让高速缓存中的数据失效, 强制从新从主内存读取数据
强制读取主内存内容, 让CPU缓存和主内存保持一致, 避免了缓存导致的一致性问题

##### JVM内存屏障

**内存屏障（memory barrier）是一个CPU指令。它是这样一条指令： a) 确保一些特定操作执行的顺序(先于这个命令的必须先执行，后于这个命令的必须后执行。)； b) 影响一些数据的可见性(强制更新一次不同CPU的缓存)**

**LoadLoad 屏障** :Load1,Loadload,Load2 确保Load1读到的数据在Load2之前可以读到。

**StoreStore 屏障** 

**LoadStore 屏障** 

**StoreLoad 屏障** 

常见的具体使用内存屏障的有几种：

1. 通过 Synchronized关键字包住的代码区域

2. 使用了volatile修饰变量,则对变量的写操作,会插入StoreLoad屏障.
