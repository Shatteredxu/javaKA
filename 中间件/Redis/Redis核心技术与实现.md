### 0.Redis有哪些常见的命令

保存键值对：set，mset。     获取：get， mget。     删除del 。判断是否否存在 exists。设置过期时间;expire,setnx,

### 1.总览：redis有什么

<img src="assets/Redis问题用户画像.png" alt="Redis问题用户画像" style="zoom:75%;" />

Redis优势：

<img src="assets/image-20220212145032075.png" alt="image-20220212145032075" style="zoom:67%;" />

### 2.Redis怎么设计的



##### 高性能

**数据结构**：支持了非常丰富，各种场景下的数据结构，各种数据结构的内存分配器提供了多种选择，分配效率也不一样

**保存在内存：**内存的访问速度一般都在百ns级别。但是，潜在的风险是一旦掉电，所有的数据都会丢失。

**键值对数据库**：**访问框架、索引模块、操作模块和存储模块**

**访问框架：**访问模式通常有两种：一种是**通过函数库调用的方式供外部应用使用**，就是以动态链接库的形式链接到我们自己的程序中，提供键值存储功能；另一种是**通过网络框架以Socket通信的形式对外提供键值对操作**，RocksDB以动态链接库的形式使用，而Memcached和Redis则是通过网络框架访问，

通过网络框架访问就需要确定**IO模型**：IO多路复用

**索引模块：**Memcached和Redis采用哈希表作为key-value索引，而RocksDB则采用跳表作为内存中key-value的索引。

**操作模块：**对于PUT和DELETE两种操作来说，除了新写入和删除键值对，还需要**分配和释放内存**

**存储模块：**持久化功能

##### 高可用

哨兵机制

##### 可扩展

集群功能

### 3.数据结构设计

<img src="assets/f204bdcf37f31c7abcee065daed8dd2d.jpg" alt="img" style="zoom:27%;" />

数据类型：字符串，*链表，字典hash*，跳跃表，整数集合，压缩列表

实现的数据结构：**字符串对象**、**列表对象**、**哈希对象**、**集合对象**和**有序集合对象**这五种类型的对象

实现从键到值的快速访问：哈希表（哈希冲突采用链地址法->过多冲突变慢->rehash操作->(渐进式rehash)）

value进行增删改查操作的效率：和**value的数据结构**有关（整数数组、双向链表、~~哈希表~~、压缩列表和跳表。）

**每个操作的复杂度：**单元素操作取决于value数据结构的复杂度,范围操作时间复杂度一般为O(n)redis2.8开始引入SCAN操作，渐进式遍历,统计集合元素个数时间复杂度为O(1),

整数数组和压缩列表在查找时间复杂度方面并没有很大的优势,但是他们的分配的是一块连续的内存空间，虽然数据结构本身没有时间复杂度的优势，**节省空间并且避免一些内存碎片产生。**

### 4.Redis的高性能IO模型

Redis是单线程，主要是指**Redis的网络IO和键值对读写是由一个线程来完成的，这也是Redis对外提供键值存储服务的主要流程**。但Redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。

redis使用单线程的原因：1、	**共享资源的安全并发访问控制**，加锁又会拖慢redis速度，2.线程切换需要保存上下文

为什么Redis单线程比多线程快：**基于多路复用的高性能I/O模型**

##### 基于多路复用的高性能I/O模型

Linux中的IO多路复用机制是指一个线程处理多个IO流，就是我们经常听到的select/epoll机制。简单来说，在Redis只运行单线程的情况下，**该机制允许内核中，同时存在多个监听套接字和已连接套接字**。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给Redis线程处理，这就实现了**一个Redis线程处理多个IO流**的效果。

linux中的select，poll，epoll

##### Redis 6.0中提出了多线程模型，为什么？

虽然单线程很快，没有锁的单线程更快借助CPU的多级缓存可以把性能发挥到最大。但是随着访问量的增加，以及数据量的增加，IO的写入写出会成为性能瓶颈。10个socket的IO吞吐处理肯定比1000个socket吞吐处理的快，为了解决这个问题，Redis6引入了IO多线程的方式以及client缓冲区，在实际指令处理还是单线程模式。在IO上变成的了【主线程】带着众多【IO线程】进行IO，IO线程听从主线程的指挥是写入还是写出。Read的时候IO线程会和主线程一起读取并且解析命令（RESP协议）存入缓冲区，写的时候会从缓冲区写出到Socket。IO线程听从主线程的指挥，在同一个时间点上主线程和IO线程会一起写出或者读取，并且主线程会等待IO线程的结束。但是这种模式的多线程会面临一给NUMA陷阱的问题，在最近的Redis版本中加强了IO线程和CPU的亲和性解决了这个问题。（不过目前官方在默认情况下并不推荐使用多线程IO模式，需要手动开启）

##### Redis单线程处理IO请求性能瓶颈主要包括2个方面：

1、任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：
         **a、**操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；
     	**b、**使用**复杂度过高的命令**：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；
		**c、**大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；
		**d、**淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；
		**e、**AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；
		**f、**主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；
		2、并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。

针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。

针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。

### 5.AOF日志

Redis的持久化主要有两大机制，即AOF日志和RDB快照

说到日志，我们比较熟悉的是**数据库的写前日志（Write Ahead Log, WAL）**，也就是说，在实际写数据前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF日志是**写后日志**，“写后”的意思是Redis是先执行命令，把数据写入内存，然后才记录日志。

**为什么？**Redis在向AOF里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis在使用日志恢复数据时，就可能会出错。还有一个好处：它是在命令执行后才记录日志，所以**不会阻塞当前的写操作**。

但是也有两个缺点：1.如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险2.AOF虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险

仔细分析的话，你就会发现，这两个风险都是和**AOF写回磁盘的时机相关**的。这也就意味着，如果我们能够控制一个写命令执行完后AOF日志写回磁盘的时机，这两个风险就解除了。

**三种写回策略**：**Always**，**Everysec**，**No**

**AOF重写压缩日志**

##### 重写会引起阻塞问题

和AOF日志由主线程写回不同，重写过程是由后台线程bgrewriteaof来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。

我把重写的过程总结为“**一个拷贝，两处日志**”。

“一个拷贝”就是指，每次执行重写时，主线程fork出后台的bgrewriteaof子进程。此时，fork会把主线程的内存拷贝一份给bgrewriteaof子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。

“两处日志”又是什么呢？

因为**主线程未阻塞**，仍然可以处理新来的操作。此时，如果有写操作，**第一处日志就是指正在使用的AOF日志，Redis会把这个操作写到它的缓冲区**。这样一来，即使宕机了，这个AOF日志的操作仍然是齐全的，可以用于恢复。

而第二处日志，就是指新的**AOF重写日志。这个操作也会被写到重写日志的缓冲区**。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的AOF文件，以保证数据库最新状态的记录。此时，我们就可以用新的AOF文件替代旧文件了。

![image-20220209175431208](assets/image-20220209175431208.png)

### 6.RDB快照

因为AOF存储的是执行的所有的命令，所以当我们需要恢复数据的时候，必须执行完所有的命令，所以RDB内存快照就是指内存中的数据在某一个时刻的状态记录

Redis提供了两个命令来生成RDB文件，分别是save和bgsave。

- save：在主线程中执行，会导致阻塞；
- bgsave：创建一个子进程，专门用于写入RDB文件，避免了主线程的阻塞，这也是Redis RDB文件生成的默认配置。

##### 快照时数据能修改吗?

Redis就会借助操作系统提供的**写时复制技术**（Copy-On-Write, COW），在执行快照的同时，正常处理写操作

如果主线程要修改一块数据（例如图中的键值对C），那么，这块数据就会被复制一份，**生成该数据的副本**。把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射然后，**bgsave会把这个副本数据写入RDB文件**，而在这个过程中，主线程仍然可以直接修改原来的数据。

##### 可以每秒做一次快照吗？

不能，因为可能会出现两个问题：1.会给磁盘带来很大压力2.前一个快照还没有做完，后一个又开始做了，容易造成恶性循环，虽然rdb快照是通过子线程来进行快照的读写，但是fork这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁fork出bgsave子进程，这就会频繁阻塞主线程了

所以我们可以做**增量快照**，所谓增量快照，就是指，做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。

而在Redis 4.0中提出了一个**混合使用AOF日志和内存快照**的方法。简单来说，内存快照以一定的频率执行，在两次快照之间，使用**AOF日志记录这期间的所有命令操作**。

RDB文件快速恢复的好处，又能享受到**AOF只记录操作命令的简单优势**，颇有点“鱼和熊掌可以兼得”的感觉

最后，关于AOF和RDB的选择问题，我想再给你提三点建议：

- 数据不能丢失时，内存快照和AOF的混合使用是一个很好的选择；
- 如果允许分钟级别的数据丢失，可以只使用RDB；
- 如果只用AOF，优先使用everysec的配置选项，因为它在可靠性和性能之间取了一个平衡。

### 7.数据同步：主从库如何实现数据一致？

Redis具有高可靠性，有两层含义：一是**数据尽量少丢失**，二是**服务尽量少中断**。AOF和RDB保证了前者，而对于后者，Redis的做法就是**增加副本冗余量**，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务。

Redis提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。

- **读操作**：主库、从库都可以接收；
- **写操作**：首先到主库执行，然后，主库将写操作同步给从库。

##### 主从库间如何进行第一次同步？

![image-20220212144543396](assets/image-20220212144543396.png)

1.**从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了**

从库给主库发送psync命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync命令包含了**主库的runID**和**复制进度offset**两个参数。

2

##### 主从库间网络断了怎么办？（增量复制）

Redis 2.8之前，如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。

从Redis 2.8开始，网络断了之后，主从库会采用增量复制的方式继续同步，主库会把断连期间收到的写操作命令，写入replication buffer，同时也会把这些操作命令也写入repl_backlog_buffer这个缓冲区。

repl_backlog_buffer是一个环形缓冲区，**主库会记录自己写到的位置，从库则会记录自己已经读到的位置**。所以可能会发现一种情况：**如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致**。所以我们需要适当增加repl_backlog_size值，来减少主从不一致的风险。

总结来说，有三种模式：全量复制、基于长连接的命令传播，以及增量复制

### 8.哨兵机制：主库挂了，如何不间断服务

哨兵就是一个运行在特殊模式下的Redis进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：**监控、选主（选择主库）和通知**。

##### 监控：（判断主库从库下线）

监控是指哨兵进程在运行时，周期性地给所有的主从库发送PING命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的PING命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的PING命令，哨兵就会判定主库下线，然后开始**自动切换主库**的流程。

**选主：（选出新一轮的主库）**

主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库

**通知：（从库和新主库建立连接，同步）**

哨兵会把新主库的连接信息发给其他从库，让它们执行replicaof命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。

##### 主观下线、客观下线

当在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下，ping命令可能会出现超时现象，但是这时的主库并没有下线，如果执行主库切换就会占用资源，所以引入了**哨兵集群**，当有N/2 + 1个实例判断主库为“主观下线”，才能最终判定主库为“客观下线

##### 如何选定主库

在多个从库中，先按照**一定的筛选条件**，把不符合条件的从库去掉。然后，我们再按照**一定的规则**，给剩下的从库逐个打分，将得分最高的从库选为新主库

打分条件：

1.**检查从库的当前在线状态，还要判断它之前的网络连接状态**，将不合格的从库筛选掉

2.**第一轮：优先级最高的从库得分高。**

3.**和旧主库同步程度最接近的从库得分高。**

4.**ID号小的从库得分高。**

##### 主库切换期间，客户端能否进行正常的请求呢？

如果客户端使用了**读写分离**，那么**读请求可以在从库上正常执行**，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间写请求会失败，**失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库** 的时间。

如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从后，再把这些写请求发给新的主库，**但这种场景只适合对写入请求返回值不敏感的业务，而且还需要业务层做适配**，另外主从切换时间过长，也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这些请求的时间变长。

哨兵检测主库多久没有响应就提升从库为新的主库，这个时间是可以配置的（down-after-milliseconds参数）。配置的时间越短，哨兵越敏感，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果配置的时间比较长，哨兵越保守，这种情况可以减少哨兵误判的概率，但是主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多。

应用程序不感知服务的中断，还需要哨兵和客户端做些什么？当哨兵完成主从切换后，客户端需要及时感知到主库发生了变更，然后把缓存的写请求写入到新库中，保证后续写请求不会再受到影响，具体做法如下：

哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于**哨兵主动通知客户端**。

如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，**客户端也需要支持主动去获取最新主从的地址进行访问。**所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。

一般Redis的SDK都提供了通过哨兵拿到实例地址，再访问实例的方式，我们直接使用即可，不需要自己实现这些逻辑。当然，对于只有主从实例的情况，客户端需要和哨兵配合使用，而在分片集群模式下，这些逻辑都可以做在proxy层，这样客户端也不需要关心这些逻辑了，Codis就是这么做的。

另外再简单回答下哨兵相关的问题：

1、哨兵集群中有实例挂了，怎么办，会影响主库状态判断和选主吗？

这个属于分布式系统领域的问题了，指的是在分布式系统中，如果存在故障节点，整个集群是否还可以提供服务？而且提供的服务是正确的？

这是一个分布式系统容错问题，这方面最著名的就是分布式领域中的“拜占庭将军”问题了，“拜占庭将军问题”不仅解决了容错问题，还可以解决错误节点的问题

2、哨兵集群多数实例达成共识，判断出主库“客观下线”后，由哪个实例来执行主从切换呢？

哨兵集群判断出主库“主观下线”后，会选出一个“哨兵领导者”，之后整个过程由它来完成主从切换。

但是如何选出“哨兵领导者”？这个问题也是一个分布式系统中的问题，就是我们经常听说的共识算法，指的是集群中多个节点如何就一个问题达成共识。共识算法有很多种，例如Paxos、Raft，这里哨兵集群采用的类似于Raft的共识算法。

### 9.哨兵集群

##### 基于pub/sub机制的哨兵集群组成

**<u>哨兵实例之间可以相互发现</u>**，要归功于Redis提供的pub/sub机制，也就是发布/订阅机制。

哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的IP地址和端口。

除了哨兵实例，我们自己编写的应用程序也可以**通过Redis进行消息的发布和订阅**。所以，为了区分不同应用的消息，Redis会以频道的形式，对这些消息进行分门别类的管理。所谓的频道，实际上就是消息的类别。当消息类别相同时，它们就属于同一个频道。反之，就属于不同的频道。**只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换**。在主从集群中，主库上有一个名为“`__sentinel__:hello`”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。

<u>**哨兵是如何知道从库的IP地址和端口的呢**</u> 哨兵向主库发送INFO命令来完成的。哨兵2给主库发送INFO命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续地对从库进行监控

##### 基于pub/sub机制的客户端事件通知

如下图所示是哨兵机制提供的比较重要的订阅频道，可以执行`SUBSCRIBE +odown`命令，来订阅“所有实例进入客观下线状态的事件”：

![image-20220213113202567](assets/image-20220213113202567.png)

##### 由哪个哨兵执行主从切换？

**Raft选举算法，**

如果哨兵集群只有2个实例，此时，一个哨兵要想成为Leader，必须获得2票，而不是1票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置3个哨兵实例。这一点很重要，你在实际应用时可不能忽略了。

##### 总结

- 基于pub/sub机制的哨兵集群组成过程；
- 基于INFO命令的从库列表，这可以帮助哨兵和从库建立连接；
- 基于哨兵自身的pub/sub功能，这实现了客户端和哨兵之间的事件通知。

假设有一个Redis集群，是“一主四从”，同时配置了包含5个哨兵实例的集群，quorum值设为2。在运行过程中，如果有3个哨兵实例都发生故障了，此时，Redis主库如果有故障，还能正确地判断主库“客观下线”吗？如果可以的话，还能进行主从库自动切换吗？此外，哨兵实例是不是越多越好呢，如果同时调大down-after-milliseconds值，对减少误判是不是也有好处呢？

- 经过实际测试，我的结论如下：

  1、哨兵集群**可以判定主库“主观下线”**。由于quorum=2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值

  2、但哨兵**不能完成主从切换**。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5/2+1=3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到多数选票的结果。

  但是投票选举过程的细节并不是大家认为的：每个哨兵各自1票，这个情况是不一定的。下面具体说一下：

  场景a：哨兵A先判定主库“主观下线”，然后马上询问哨兵B（注意，此时哨兵B只是被动接受询问，并没有去询问哨兵A，也就是它还没有进入判定“客观下线”的流程），哨兵B回复主库已“主观下线”，达到quorum=2后哨兵A此时可以判定主库“客观下线”。此时，哨兵A马上可以向其他哨兵发起成为“哨兵领导者”的投票，哨兵B收到投票请求后，由于自己还没有询问哨兵A进入判定“客观下线”的流程，所以哨兵B是可以给哨兵A投票确认的，这样哨兵A就已经拿到2票了。等稍后哨兵B也判定“主观下线”后想成为领导者时，因为它已经给别人投过票了，所以这一轮自己就不能再成为领导者了。

  场景b：哨兵A和哨兵B同时判定主库“主观下线”，然后同时询问对方后都得到可以“客观下线”的结论，此时它们各自给自己投上1票后，然后向其他哨兵发起投票请求，但是因为各自都给自己投过票了，因此各自都拒绝了对方的投票请求，这样2个哨兵各自持有1票。

  场景a是1个哨兵拿到2票，场景b是2个哨兵各自有1票，这2种情况都不满足大多数选票(3票)的结果，因此无法完成主从切换。

  经过测试发现，场景b发生的概率非常小，只有2个哨兵同时进入判定“主观下线”的流程时才可以发生。我测试几次后发现，都是复现的场景a。

  哨兵实例是不是越多越好？

  并不是，我们也看到了，哨兵在判定“主观下线”和选举“哨兵领导者”时，都需要和其他节点进行通信，交换信息，哨兵实例越多，通信的次数也就越多，而且部署多个哨兵时，会分布在不同机器上，节点越多带来的机器故障风险也会越大，这些问题都会影响到哨兵的通信和选举，出问题时也就意味着选举时间会变长，切换主从的时间变久。

  调大down-after-milliseconds值，对减少误判是不是有好处？

  是有好处的，适当调大down-after-milliseconds值，当哨兵与主库之间网络存在短时波动时，可以降低误判的概率。但是**调大down-after-milliseconds值也意味着主从切换的时间会变长**，对业务的影响时间越久，我们需要根据实际场景进行权衡，设置合理的阈值。

### 10.切片集群：数据增多了，是该加内存还是加实例？

**切片集群，也叫分片集群**，就是指启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。如果把25GB的数据平均分成5份（当然，也可以不做均分），使用5个实例来保存，每个实例只需要保存5GB数据。

##### 如何保存更多数据？

分为**大内存云主机**和**切片集群**两种方法，对应纵向扩展（scale up）和横向扩展（scale out）两种方案

##### 数据切片和实例的对应分布关系

- 数据切片后，在多个实例之间如何分布？

> Redis Cluster方案采用哈希槽（Hash Slot，接下来我会直接称之为Slot），来处理数据和实例之间的映射关系。在Redis Cluster方案中，一个切片集群共有16384个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的key，被映射到一个哈希槽中,每个机器都会分配一定数量的槽，然后根据根据键值对的key，按照[CRC16算法](https://en.wikipedia.org/wiki/Cyclic_redundancy_check)计算一个16 bit的值；然后，再用这个16bit值对16384取模，得到0~16383范围内的模数，每个模数代表一个相应编号的哈希槽
>
> 注意：**在手动分配哈希槽时，需要把16384个槽都分配完，否则Redis集群无法正常工作**。

- 客户端怎么确定想要访问的数据在哪个实例上？

> 正常情况下通过计算得到槽再哪个实例上，如果发生数据迁移，则重定向
>
> Redis Cluster方案提供了一种**重定向机制，**所谓的“重定向”，就是指，客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令

### 11.“万金油”的String，为什么不好用了？

##### 字符串占用内存分析

Redis中使用字符串内存开销：1.SDS(**alloc**实际分配长度4B, **len **buf的已用长度4B,**buf**保存实际数据,\0结尾会多一个字节)

SDS的额外开销，还有一个来自于**RedisObject结构体**的开销。不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间、被引用的次数等），所以，Redis会用一个RedisObject结构体来统一记录这些元数据，同时指向实际数据。

<img src="assets/image-20220214144242816.png" alt="image-20220214144242816" style="zoom:67%;" />

为了节省内存空间，Redis还对**Long类型整数**和**SDS的内存布局**做了专门的设计。

一方面，当保存的是Long类型整数时，RedisObject中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。

另一方面，当保存的是字符串数据，并且字符串小于等于44字节时，RedisObject中的元数据、指针和SDS是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为**embstr编码方式**。

当然，当字符串大于44字节时，SDS的数据量就开始变多了，Redis就不再把SDS和RedisObject布局在一起了，而是会给SDS分配独立的空间，并用指针指向SDS结构。这种布局方式被称为**raw编码模式**

<img src="assets/image-20220214144859280.png" alt="image-20220214144859280" style="zoom:67%;" />

Redis会使用一个全局哈希表保存所有键值对，哈希表的每一项是一个dictEntry的结构体，用来指向一个键值对。dictEntry结构中有三个8字节的指针，分别指向key、value以及下一个dictEntry，三个指针共24字节

<img src="assets/image-20220214144941887.png" alt="image-20220214144941887" style="zoom:70%;" />

jemalloc在分配内存时，会根据我们申请的字节数N，找一个比N大，但是最接近N的2的幂次数作为分配的空间，这样可以减少频繁分配的次数。所以上面虽然只有24字节，但是会分配32字节的内存。

##### 用什么数据结构可以节省内存？

表头有三个字段zlbytes、zltail和zllen，分别表示列表长度、列表尾的偏移量，以及列表中的entry个数。压缩列表尾还有一个zlend，表示列表结束

<img src="assets/image-20220214145127574.png" alt="image-20220214145127574" style="zoom:67%;" />

其中每一个entry包含**prev_len**（前一个entry的长度，1B或者4B），**len**（自身长度,4B），**encoding**（编码方式，1B）**content**(实际数据)

##### 如何用集合类型保存单值的键值对？

在保存单值的键值对时，可以采用基于Hash类型的二级编码方法。这里说的二级编码，就是把一个单值的数据拆分成两部分，前一部分作为Hash集合的key，后一部分作为Hash集合的value，这样一来，我们就可以把单值数据保存到Hash集合中了。

**二级编码方法中采用的ID长度是有讲究的**，因为Redis规定我们往Hash集合中写入的元素个数**超过了hash-max-ziplist-entries**（哈希集合中的最大元素个数），或者写入的单个元素大小超过了hash-max-ziplist-value（单个元素的最大长度），Redis就会自动把Hash类型的实现结构由压缩列表转为哈希表

**为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在Hash集合中的元素个数**

但是采用压缩列表来存储时，存储的元素不应该太多，太多会导致查询性能下降，而且压缩列表可能导致级联膨胀

另外，使用Hash和Sorted Set存储时，虽然节省了内存空间，但是设置过期变得困难（无法控制每个元素的过期，只能整个key设置过期，或者业务层单独维护每个元素过期删除的逻辑，但比较复杂）。而使用String虽然占用内存多，但是每个key都可以单独设置过期时间，还可以设置maxmemory和淘汰策略，以这种方式控制整个实例的内存上限。

##### 总结：

**Redis中的字符串简单，可以自己设置过期时间，但是占用内存比较多，而压缩列表占用内存比较小，但是可能会出现级联膨胀，并且查询性能比较差**

### 12.有一亿个keys要统计，应该用哪种集合？

##### 聚合统计

统计多个集合元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个集合相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计）。

##### 排序统计

再Redis数据结构中List，SortSet都是有序的，List集合时按照插入顺序来排序的，而SortSet时按照字段进行排序，但是在一些场景，比如分页展示商品评论，如果按照插入顺序，当我们显示第一页后，就可能会有新的元素插入进来，这时先前的插入顺序就会失效，所以在一些有字段进行排序的任务下，采用SortSet会更好

##### 二值状态统计

二值状态统计。这里的二值状态就是指集合元素的取值就只有0和1两种。在签到打卡的场景中，我们只用记录签到（1）或未签到（0），所以它就是非常典型的二值状态，

Bitmap本身是用String类型作为底层数据结构实现的一种统计二值状态的数据类型。String类型是会保存为二进制的字节数组，所以，Redis就把字节数组的每个bit位利用起来，用来表示一个元素的二值状态。你可以把Bitmap看作是一个bit数组。使用SETBIT ，GETBIT ，BITCOUNT (查看1的总数)，Bitmap支持用BITOP命令对多个Bitmap按位做“**与”“或”“异或”**的操作，操作的结果会保存到一个新的Bitmap中。

##### 基数统计

基数统计就是指统计一个集合中不重复的元素个数。类似统计网页的UV。UV统计需要我们去重，如果时重复的元素则不加入，虽然Set,Hash都可以实现去重的功能，但是这两个数据结构会随着元素增多，占用空间变大，所以就要用到Redis提供的**HyperLogLog**了。

HyperLogLog是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。

在Redis中，每个 HyperLogLog只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的Set和Hash类型相比，**HyperLogLog就非常节省空间**

<img src="assets/redis数据结构所支持的统计方法.png" alt="redis数据结构所支持的统计方法" style="zoom:67%;" />

### 13.GEO是什么？还可以定义新的数据类型吗？

面对海量数据时，使用基本数据类型内存开销很大，而且对于一些特殊的场景是无法支持的。所以，Redis还提供了3种扩展数据类型，分别是**Bitmap、HyperLogLog和GEO**。

##### 应用场景

日常生活中，我们越来越依赖搜索“附近的餐馆”、在打车软件上叫车，这些都离不开基于**位置信息服务（Location-Based Service，LBS）的应用**。LBS应用访问的数据是和人或物关联的一组<u>经纬度信息</u>，而且要能查询相<u>邻的经纬度范围</u>，GEO就非常适合应用在LBS服务的场景中

##### GEO的底层结构

首先分析一下LBS情景的特点：

1.  每一辆网约车都有一个**编号**（例如33），网约车需要将自己的**经度信息**（例如116.034579）和纬度信息（例如39.000452 ）发给叫车应用。
2.  用户在叫车的时候，叫车应用会根据用户的经纬度位置（例如经度116.054579，纬度39.030452），查找用户的**附近车辆，并进行匹配。**
3. 等把位置相近的用户和车辆匹配上以后，叫车应用就会**根据车辆的编号，获取用户附近的车辆的信息**，并返回给用户。

首先我们可能会想到使用**hash进行存储**，但是一旦**涉及到范围查询**，就意味着集合中的元素需要有序，但Hash类型的元素是无序的，所以根据范围查询就不能满足我们的要求。

那么**Sorted Set类型**是不是合适呢？Sorted Set类型也支持一个key对应一个value的记录模式，其中，key就是Sorted Set中的元素，而value则是元素的权重分数。更重要的是，**Sorted Set可以根据元素的权重分数排序，支持范围查询**。这就能满足LBS服务中查找相邻位置的需求了。但是原本的sorted set的value使用的是浮点数，而我们LBS应用value为经纬度两个，所以我们需要改变一下。

##### GeoHash的编码方法

Redis采用了业界广泛使用的GeoHash编码方法，这个方法的基本原理就是**“二分区间，区间编码”**。当我们要对一组经纬度进行GeoHash编码时，我们要先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码。

<img src="assets/3cb007yy63c820d6dd2e4999608683f2.jpg" alt="img" style="zoom:37%;" />

如上图，我们可以吧经纬度分成一个一个区间，当拿到一个经纬度值的时候，我们根据这个经纬度所处的区间，如果在这个区间，则第一位编码为1，否则为0,这样一步一步细分下去，有多少个区间就会分配多少个编码，<u>分区越多，每个方格能覆盖到的地理空间就越小，也就越精准</u>，通过这个编码方式的sorted set我们就能够使用hash来进行区间查找了，

<img src="assets/0d64c9765ab72a50abef16a0275bc0ba.jpg" alt="img" style="zoom:20%;" />

##### 操作GEO

在使用GEO类型时，我们经常会用到两个命令，分别是GEOADD和GEORADIUS。

- GEOADD命令：用于把一组经纬度信息和相对应的一个ID记录到GEO类型集合中；
- **GEORADIUS命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素**。当然，我们可以自己定义这个范围。

##### redis自定义数据类型

<img src="assets/88702464f8bc80ea11b26ab157926199.jpg" alt="img" style="zoom:67%;" />

##### 留言精选

<u>Redis也可以使用List数据类型当做队列使用</u>，rpush生产数据到Redis中，客户端使用lpop取出数据进行消费，基于内存存取非常快速，但是List没有ack机制和不支持多个消费者,所以适合那些对数据不敏感的业务。

Redis提供的PubSub，可以支持多个消费者进行消费，生产者发布一条消息，多个消费者同时订阅消费，如果任意一个消费者挂了，等恢复过来后，**在这期间的生产者的数据就丢失了**。PubSub只把数据发给在线的消费者，**消费者一旦下线，就会丢弃数据**。另一个缺点是，**PubSub中的数据不支持数据持久化**，当Redis宕机恢复后，其他类型的数据都可以从RDB和AOF中恢复回来，但PubSub不行

Redis 5.0推出了**Stream数据结构**，它借鉴了Kafka的设计思想，弥补了List和PubSub的不足。Stream类型数据可以持久化、支持ack机制、支持多个消费者、支持回溯消费，基本上实现了队列中间件大部分功能，比List和PubSub更可靠。

**基于Redis实现的布隆过滤器**，其底层实现利用的是String数据结构和位运算，可以解决业务层缓存穿透的问题，而且内存占用非常小，操作非常高效

### 14.Redis中保存时间序列数据

时间序列数据特点：需要持续高并发写入，不会存在更新数据，，所以我们需要插入数据快的数据结构。在进行数据插入时，复杂度要低，尽量不要阻塞

而时间序列数据的查询：1.单条记录的查询2.某个时间范围内的数据的查询3.某个时间范围内的数据做聚合计算。

Redis提供了保存时间序列数据的两种方案，分别可以**基于Hash和Sorted Set实现**，以及**基于RedisTimeSeries模块**实现。

##### 基于Hash和Sorted Set保存时间序列数据

Hash可以保证单个键查询的速度，我们可以把时间戳作为Hash集合的key，把记录的设备状态值作为Hash集合的value，使用HGET命令或者HMGET命令获取某个时间的值。

但Hash类型不支持对数据进行范围查询。所以为了能同时支持按时间戳范围的查询，可以用<u>Sorted Set来保存时间序列数据</u>，因为它能够根据元素的权重分数来排序。可以把时间戳作为Sorted Set集合的元素分数，把时间点 记录的数据作为元素本身，使用ZRANGEBYSCORE命令，按照输入的最大时间戳和最小时间戳来查询这个时间范围内的温度值。

##### 基于RedisTimeSeries模块保存时间序列数据

RedisTimeSeries是Redis的一个扩展模块。面向时间序列数据提供了数据类型和访问接口，支持在Redis实例上直接对数据进行<u>按时间范围的聚合计算</u>

RedisTimeSeries的操作主要有5个：

*   用TS.CREATE命令创建时间序列数据集合；
*   用TS.ADD命令插入数据；
*   用TS.GET命令读取最新数据；
*   用TS.MGET命令按标签过滤查询数据集合；
*   用TS.RANGE支持聚合计算的范围查询。

RedisTimeSeries是专门为<u>时间序列数据访问</u>设计的扩展模块，能支持在Redis实例上直接进行**聚合计算**，以及按**标签属性过滤**查询数据集合，当我们需要频繁进行聚合计算，以及从大量集合中筛选出特定设备或用户的数据集合时，RedisTimeSeries就可以发挥优势了。

### 15.Redis用作消息队列

消息队列的消息读取有什么样的需求？**消息保序、处理重复的消息和保证消息可靠性。**

Redis的List和Streams两种数据类型，就可以满足消息队列的这三个需求

##### 基于List的消息队列解决方案

1.   List本身就是按先进先出的顺序对数据进行存取，**（天然保序）**

     >   生产者可以使用LPUSH命令把要发送的消息依次写入List，而消费者则可以使用RPOP命令,不过List不会主动地通知消费者有新消息写入，如果消费者想要及时处理消息，就需要在程序中不停地调用RPOP命令
     >
     >   为了解决这个问题，Redis提供了BRPOP命令。**BRPOP命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据**

2.   需要一个全局唯一ID来保证消息的幂等性

     >   List本身是不会为每个消息生成ID号的，所以，消息的全局唯一ID号就需要生产者程序在发送消息前自行生成。生成之后，我们在用LPUSH命令把消息插入List时，需要在消息中包含这个全局唯一ID。

3.   List类型提供了BRPOPLPUSH命令,保证消息的可靠性

     >   BRPOPLPUSH命令的作用是让消费者程序<u>从一个List中读取消息</u>，同时，Redis会把这个消息再插入到另一个List（可以叫作备份List）留存

4.   当我们需要多个消费组进行消费，这是基于List就不能满足了

##### 基于Streams的消息队列解决方案

Streams是Redis专门为消息队列设计的数据类型，它提供了丰富的消息队列操作命令。

*   XADD：插入消息，保证有序，可以自动生成全局唯一ID；`XADD mqstream * repo 5`
*   XREAD：用于读取消息，可以按ID读取数据；(没有数据则会阻塞)
*   XREADGROUP：按消费组形式读取消息；(同一个消费组中的一个消费者读取了消息，其他消费者就无法在读取)
*   XPENDING和XACK：XPENDING命令可以用来查询每个消费组内所有消费者已读取但尚未确认的消息，而XACK命令用于向消息队列确认消息处理已完成。

##### 总结

如果分布式系统中的组件消息通信量不大，那么，Redis只需要使用有限的内存空间就能满足消息存储的需求

但是如果对场景要求比较高，可靠性要求比较高，可以使用Kafka、RabbitMQ这些专门面向消息队列场景的软件

### 16.异步机制：避免单线程模型的阻塞

Redis实例有哪些阻塞点？如下图

>   *   **客户端**：网络IO，键值对增删改查操作，数据库操作；
>   *   **磁盘**：生成RDB快照，记录AOF日志，AOF日志重写；
>   *   **主从节点**：主库生成、传输RDB文件，从库接收RDB文件、清空数据库、加载RDB文件；
>   *   **切片集群实例**：向其他实例传输哈希槽信息，数据迁移。

<img src="assets/6ce8abb76b3464afe1c4cb3bbe426922.jpg" alt="img" style="zoom:25%;" />

##### 1.和客户端交互时的阻塞点

1.   网络IO:Redis使用了IO多路复用机制，避免了主线程一直处在等待网络连接或请求到来的状态（不会阻塞）
2.   增删改查操作，大量的增删改查操作(big key删除)，复杂度高的操作（超过O(n)），清空数据库

##### 2.和磁盘交互时的阻塞点

主要集中在AOF,RDB操作上，所以需要控制好AOF和RDB快照的生成时间，并采用子线程去读写、

Redis直接记录AOF日志时，会根据不同的写回策略对数据做落盘保存。一个同步写磁盘的操作的耗时大约是1～2ms，如果有大量的写操作需要记录在AOF日志中，并同步写回的话，就会阻塞主线程了。这就得到了Redis的**第四个阻塞点了：AOF日志同步写**

##### 3.主从节点交互时的阻塞点

主库需要生成RDB文件，并传输给从库。主库在复制的过程中，创建和传输RDB文件都是由子进程来完成的，不会阻塞主线程。但是，对于从库来说，它在接收了RDB文件后，需要使用FLUSHDB命令清空当前数据库，这就正好撞上了刚才我们分析的**第三个阻塞点。**从库在清空当前数据库后，还需要把RDB文件加载到内存，这个过程的快慢和RDB文件的大小密切相关，RDB文件越大，加载过程越慢，所以，**加载RDB文件就成为了Redis的第五个阻塞点**。

##### 4.切片集群实例交互时的阻塞点

当我们部署<u>Redis切片集群</u>时，每个Redis实例上分配的哈希槽信息需要在不同实例间进行传递，同时，当需要进行负载均衡或者有实例增删时，数据会在不同的实例间进行迁移。不过，哈希槽的信息量不大，而数据迁移是渐进式执行的，所以，一般来说，这两类操作对Redis主线程的阻塞风险不大

不过，如果你使用了Redis Cluster方案，而且同时正好迁移的是bigkey的话，就会造成主线程的阻塞，因为Redis Cluster使用了同步迁移

##### 怎么解决上面的问题

首先我们考虑将上面的操作进行异步执行，所以问题来了：上面五大阻塞式操作都可以被异步执行吗？

*   集合全量查询和聚合操作；（查询和聚合都涉及读操作，不能异步执行）
*   bigkey删除；(可以异步执行)
*   清空数据库；(可以)
*   AOF日志同步写；(可以使用子线程)
*   从库加载RDB文件。(不能异步执行)

##### 异步的子线程机制

Redis主线程启动后，会使用操作系统提供的pthread_create函数创建3个子线程，分别由它们负责AOF日志写操作、键值对删除以及文件关闭的异步执行。

主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。

<img src="assets/ae004728bfe6d3771c7424e4161e7969.jpg" alt="img" style="zoom:33%;" />

### 17.CPU结构对Redis的性能

##### 主流CPU架构和NUMA架构

一个CPU处理器中一般有多个运行核心，称为一个物理核，每个物理核都可以运行应用程序。每个物理核都拥有私有的一级缓存L1 cache，包括一级指令缓存和一级数据缓存，以及私有的二级缓存（Level 2 cache，简称L2 cache），不同的物理核还会共享一个共同的三级缓存L3 cache，每个物理核通常都会运行两个超线程，也叫作逻辑核。同一个物理核的逻辑核会共享使用L1、L2缓存。

<img src="assets/d9689a38cbe67c3008d8ba99663c2f09.jpg" alt="img" style="zoom:20%;" />

在主流的服务器上，一个CPU处理器会有10到20多个物理核。还会有多个CPU处理器（也称为**多CPU Socket**），每个处理器有自己的物理核（包括L1、L2缓存），L3缓存，以及连接的内存，同时，不同处理器间通过总线连接。不过不同CPU通过总线进行通信，但是会增加耗时

<img src="assets/5ceb2ab6f61c064284c8f8811431bc3d.jpg" alt="img" style="zoom:20%;" />

在多CPU架构下，一个应用程序访问所在Socket的本地内存和访问远端内存的延迟并不一致，我们把这个架构称为非统一内存访问架构（Non-Uniform Memory Access，**NUMA架构**）。

##### CPU多核对Redis性能的影响

项目需求是要对Redis的99%<u>尾延迟</u>进行优化，要求GET尾延迟小于300微秒，PUT尾延迟小于500微秒。

刚开始的时候，我们使用GET/PUT复杂度为O(1)的String类型进行数据存取，同时关闭了RDB和AOF，而且，Redis实例中没有保存集合类型的其他数据，也就没有bigkey操作，避免了可能导致延迟增加的许多情况。

但是，即使这样，我们在一台有24个CPU核的服务器上运行Redis实例，GET和PUT的99%尾延迟分别是504微秒和1175微秒，明显大于我们设定的目标。

检测了Redis实例运行时的服务器CPU的状态指标值，发现CPU的context switch次数比较多。当context switch发生后，Redis主线程的运行时信息需要被重新加载到另一个CPU核上，而且，此时，另一个CPU核上的L1、L2缓存中，并没有Redis实例之前运行时频繁访问的指令和数据，所以，这些指令和数据都需要重新从L3缓存，甚至是内存中加载。这个重新加载的过程是需要花费一定时间的。而且，Redis实例需要等待这个重新加载的过程完成后，才能开始处理请求，所以，这也会导致一些请求的处理时间增加。并且<u>CPU切换保存上下文也是需要时间</u>

**解决办法：**使用**taskset命令**把一个程序绑定在一个核上运行。后来发现绑定后，尾延迟下降了很多，达到了要求

##### CPU的NUMA架构对Redis性能的影响

在实际应用Redis时，为了提升Redis的网络性能，把操作系统的网络中断处理程序和CPU核绑定。这个做法可以**避免网络中断处理程序在不同核上来回调度执行**，能有效提升Redis的网络处理性能。

但是网络中断程序和redis实例需要进行数据交互操作的，如果两者被绑定在了不同的CPU处理器上，那么**Redis实例读取网络数据时，就需要跨CPU Socket访问内存，这个过程会花费较多时间。**所以在绑定的时候我们需要注意，将两者放在一个CPU处理器上，避免远端访问。



**CPU核的编号规则**：先给每个CPU Socket中每个物理核的第一个逻辑核依次编号，再给每个CPU Socket中的物理核的第二个逻辑核依次编号，假设有2个CPU Socket，每个Socket上有6个物理核，每个物理核又有2个逻辑核，总共24个逻辑核，先对每个CPU的每个物理核的第一个逻辑核进行编号，依次是`NUMA node0 CPU(s): 0-5,12-17 NUMA node1 CPU(s): 6-11,18-23`

##### 绑核的风险和解决方案

当我们把Redis实例绑到一个CPU逻辑核上时，就会导致子进程、后台线程和Redis主线程竞争CPU资源，一旦子进程或后台线程占用CPU时，主线程就会被阻塞，导致Redis请求延迟增加。

针对这种情况，我来给你介绍两种解决方案，分别是**一个Redis实例对应绑一个物理核和优化Redis源码。**

**一个Redis实例对应绑一个物理核**:在绑核时将Redis实例绑定到了逻辑核0和12上，而这两个核正好都属于物理核1。可以在一定程度上缓解CPU资源竞争，但是竞争任然存在。

**优化Redis源码**：修改Redis源码，把子进程和后台线程绑到不同的CPU核上



### 18.变慢的Redis：波动的响应延迟(上)

查看Redis的<u>响应延迟</u>来确定Redis是否变慢：`redis-cli --latency -h  host -p port`可以用来监测和统计测试期间内的最大延迟，这个延迟可以作为Redis的基线性能，所以当<u>观察到的Redis运行时延迟是其基线性能的2倍及以上</u>，就可以认定Redis变慢了。

查看网络性能：使用**iPerf工具**

##### Redis自身操作特性导致变慢

由于使用命令对键值对进行操作：慢查询命令和过期key操作。

**<u>*1.使用慢查询命令：*</u>**通过**Redis日志**，或者是**latency monitor工具**，查询变慢的请求，根据请求对应的具体命令以及官方文档，确认下是否采用了复杂度高的慢查询命令。

1.   可以采用高效的命令，当获取，删除操作的时候采用渐进式，避免一次性操纵大量的数据
2.   **需要执行排序、交集、并集操作时，可以在客户端完成，而不要用SORT、SUNION、SINTER这些命令，以免拖慢Redis实例**。
3.   KEYS返回和输入模式匹配的所有key，

**<u>*2.过期key操作*</u>**

由于使用EXPIREAT命令设置key过期时间时，使用了相同的UNIX时间戳，或者使用EXPIRE命令给批量的key设置**相同的过期秒数**，我们需要在设置过期时间时候加上一个随机的时间，避免大量key在同一时间过期。

### 19.变慢的Redis：波动的响应延迟(下)

上节课说了Redis变慢可以是由于自身操作(慢查询命令，key大量过期)，但是如果这些都没有，就需要考虑<u>文件系统和操作系统</u>。

##### 文件系统

为了保证数据可靠性，Redis会采用AOF日志或RDB快照。其中，AOF日志提供了三种日志写回策略：no、everysec(每秒调用一次fsync)、always(每个操作都会调用fsync)。这三种写回策略依赖文件系统的两个系统调用完成，也就是**write和fsync。**write只要把日志记录写到内核缓冲区，就可以返回了；fsync需要把日志记录写回到磁盘后才能返回，时间较长。

##### 操作系统：swap

内存swap是操作系统里将内存数据在内存和磁盘间来回换入和换出的机制，涉及到磁盘的读写，所以，一旦触发swap，无论是被换入数据的进程，还是被换出数据的进程，其性能都会受到慢速磁盘读写的影响。

触发swap的原因主要是**物理机器内存不足**，有两种情况：

1.   Redis实例自身使用了大量的内存，导致物理机器的可用内存不足；
2.   和Redis实例在同一台机器上运行的其他进程，在进行大量的文件读写操作。文件读写本身会占用系统内存，这会导致分配给Redis实例的内存量变少，进而触发Redis发生swap。

解决办法：加内存，使用集群分担压力



##### 操作系统：内存大页

Linux内核从2.6.38开始支持内存大页机制，该机制支持2MB大小的内存页分配，而常规的内存页分配是按4KB的粒度来执行的。

虽然内存大页可以给Redis带来内存分配方面的收益，但是Redis为了提供数据可靠性保证，需要将数据做持久化保存。这个写入过程由额外的线程执行，所以，此时，Redis主线程仍然可以接收客户端写请求。客户端的写请求可能会修改正在进行持久化的数据。在这一过程中，Redis就会采用写时复制机制，也就是说，一旦有数据要被修改，Redis并不会直接修改内存中的数据，而是将这些数据拷贝一份，然后再进行修改。

如果采用了内存大页，那么，即使客户端请求只修改100B的数据，Redis也需要拷贝2MB的大页。相反，如果是常规内存页机制，只用拷贝4KB。

### 20.内存碎片对Redis的影响

##### 内存碎片是如何形成的

1.操作系统的内存分配机制，2.Redis自身删改操作。



**内存分配器**一般是按固定大小来分配内存，而不是完全按照应用程序申请的内存空间大小给程序分配。当我们申请了20字节的空间保存数据，jemalloc就会分配32字节，此时，如果应用还要写入10字节的数据，Redis就不用再向操作系统申请空间了，直接复用之前已经申请的。redis内存分配器可以使用libc、jemalloc、tcmalloc多种内存分配器来分配内存，默认使用**jemalloc**

**Redis申请内存空间**时，需要的内存大小不一致，这就可能导致内部碎片的形成，大量的内存碎片就可能是内存利用率大大降低，比如拥有16GB的内存，但是存储了8GB的数据

##### 如何判断是否有内存碎片？

Redis自身提供了INFO命令`INFO memory ` ，可以用来查询内存使用的详细信息，`mem_fragmentation_ratio`表示的就是Redis当前的内存碎片率

*   **mem_fragmentation_ratio 大于1但小于1.5**。这种情况是合理的。这是因为，刚才我介绍的那些因素是难以避免的。毕竟，内因的内存分配器是一定要使用的，分配策略都是通用的，不会轻易修改；而外因由Redis负载决定，也无法限制。所以，存在内存碎片也是正常的。
*   **mem_fragmentation_ratio 大于 1.5** 。这表明内存碎片率已经超过了50%。一般情况下，这个时候，我们就需要采取一些措施来降低内存碎片率了。
*   **mem_fragmentation_ratio <1时候**，说明used_memory_rss小于了used_memory，这意味着操作系统分配给Redis进程的物理内存，要小于Redis实际存储数据的内存，也就是说Redis没有足够的物理内存可以使用了，这会导致Redis一部分内存数据会被换到Swap中，之后当Redis访问Swap中的数据时，延迟会变大，性能下降。

##### 如何清理内存碎片？

1.   重启Redis，缺点就是1. 数据丢失，2.如果使用AOF或RDB进行恢复，恢复时长取决于AOF或RDB的大小，不可控。

2.   从4.0-RC3版本以后，Redis自身提供了一种内存碎片自动清理的方法,不过由于Redis是单线程的，所以清理时会阻塞主线程的其他操作，所以我们可以设置参数，在适当的时候进行清理

     >   *   **active-defrag-ignore-bytes 100mb**：表示内存碎片的字节数达到100MB时，开始清理；
     >   *   **active-defrag-threshold-lower 10**：表示内存碎片空间占操作系统分配给Redis的总空间比例达到10%时，开始清理。
     >   *   **active-defrag-cycle-min 25**： 表示自动清理过程所用CPU时间的比例不低于25%，保证清理能正常开展；
     >   *   **active-defrag-cycle-max 75**：表示自动清理过程所用CPU时间的比例不高于75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞Redis，导致响应延迟升高

### 21.缓冲区可能出现的问题

缓冲区就是用一块内存空间来暂时存放命令数据，以免出现因为数据和命令的处理速度慢于发送速度而导致的数据丢失和性能问题

##### 客户端输入和输出缓冲区

输入缓冲区会先把客户端发送过来的命令暂存起来，Redis主线程再从输入缓冲区中读取命令，进行处理。当Redis主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端，如下图所示：

<img src="assets/b86be61e91bd7ca207989c220991fce4-16504565351253.jpg" alt="img" style="zoom:20%;" />

##### 如何查看和应对输入缓冲区溢出？

输入缓冲区就是用来暂存客户端发送的请求命令的，所以可能导致溢出的情况主要是下面两种：

*   写入了bigkey，比如一下子写入了多个百万级别的集合类型数据；
*   服务器端处理请求的速度过慢，例如，Redis主线程出现了间歇性阻塞，无法及时处理正常发送的请求，导致客户端发送的请求在缓冲区越积越多。

**使用CLIENT LIST命令**可以看到每个客户端输入缓存区的情况。

重点关注两类信息就可以了。

一类是与**服务器端连接的客户端的信息**。这个案例展示的是一个客户端的输入缓冲区情况，如果有多个客户端，输出结果中的addr会显示不同客户端的IP和端口号。

另一类是与**输入缓冲区相关**的三个参数：

*   cmd，表示客户端最新执行的命令。这个例子中执行的是CLIENT命令。
*   <u>qbuf，表示输入缓冲区已经使用的大小</u>。
*   <u>qbuf-free，表示输入缓冲区尚未使用的大小</u>。qbuf和qbuf-free的总和就是，Redis服务器端当前为已连接的这个客户端分配的缓冲区总大小。

Redis的客户端**输入缓冲区**大小的上限阈值，在代码中就设定为了1GB。一般情况都是够用的，所以除非更改代码，一般是没有参数去更改的，所以我们要**避免客户端写入bigkey，以及避免Redis主线程阻塞。**

##### 如何应对输出缓冲区溢出？

Redis的输出缓冲区暂存的是Redis主线程要返回给客户端的数据。Redis为每个客户端设置的输出缓冲区也包括两部分：一部分，是一个大小为16KB的**固定缓冲空间**，用来暂存OK响应和出错信息；另一部分，是一个可以**动态增加的缓冲空间**，用来暂存大小可变的响应结果。

什么情况下会发生输出缓冲区溢出？

*   服务器端返回bigkey的大量结果；

*   执行了MONITOR命令；

    >   MONITOR命令是用来监测Redis执行的。执行这个命令之后，就会持续输出监测到的各个命令操作,**MONITOR的输出结果会持续占用输出缓冲区**，并越占越多，最后的结果就是发生溢出，所以MONITOR的输出结果会持续占用输出缓冲区，并越占越多，最后的结果就是发生溢出

*   缓冲区大小设置得不合理。

    >   使用client-output-buffer-limit来设置缓冲区大小：
    >
    >   *   设置缓冲区大小的上限阈值；
    >   *   设置输出缓冲区持续写入数据的数量上限阈值，和持续写入数据的时间的上限阈值。

##### 主从集群中的缓冲区

主从集群间的数据复制包括**全量复制和增量复制**两种。全量复制是同步所有数据，而增量复制只会把主从库网络断连期间主库收到的命令，同步给从库。

**全量复制缓存区：**主节点上复制缓冲区的内存开销，会是每个从节点客户端输出缓冲区占用内存的总和。如果集群中的从节点数非常多的话，主节点的内存开销就会非常大。所以，我们还必须得控制和主节点连接的从节点个数，不要使用大规模的主从集群。

**增量复制缓存区：**repl_backlog_buffer，是一个大小有限的环形缓冲区。当主节点把复制积压缓冲区写满后，会覆盖缓冲区中的旧命令数据。如果从节点还没有同步这些旧命令数据，就会造成主从节点间重新开始执行全量复制，

### 22.常见问题答疑

##### Redis的其它数据类型

除了基本的5大数据类型外，还有HyperLogLog、Bitmap、GEO，布隆过滤器

##### Sorted Set保存时间序列数据的问题

在用Sorted Set保存时间序列数据时，如果把时间戳作为score，把实际的数据作为member，这样保存数据有没有潜在的风险？

答：Sorted Set和Set一样，都会对集合中的元素进行去重，这种**去重的特性是会带来数据丢失风险的**。

关于是否把聚合计算作为Sorted Set的内在功能，考虑到Redis的读写功能是由单线程执行，在进行数据读写时，本身就会消耗较多的CPU资源，如果再在Sorted Set中实现聚合计算，就会进一步增加CPU的资源消耗，影响到Redis的正常数据读取。所以，如果我是Redis的开发维护者，除非对Redis的线程模型做修改，比如说在Redis中使用额外的线程池做聚合计算，否则，我不会把聚合计算作为Redis的内在功能实现的。

##### 如何绑核

在一台有两个CPU Socket（每个Socket 8个物理核）的服务器上，我们部署了一个有着**8个实例的Redis切片集群**（8个实例都为主节点，没有主备关系），现在有两个方案：

1.  在同一个CPU Socket上运行8个实例，并和8个CPU核绑定；
2.  在两个CPU Socket上各运行4个实例，并和相应Socket上的核绑定。

如果不考虑网络数据读取的影响，你会选择哪个方案呢？

答案：**建议使用第二个方案**，主要有两方面的原因。

1.  同一个CPU Socket上的进程，会共享L3缓存。如果把8个实例都部署在同一个Socket上，它们会竞争L3缓存，这就会导致它们的L3缓存命中率降低，影响访问性能。
2.  同一个CPU Socket上的进程，会使用同一个Socket上的内存空间。<u>8个实例共享同一个Socket上的内存空间，肯定会竞争内存资源</u>。如果有实例保存的数据量大，其他实例能用到的内存空间可能就不够了，此时，其他实例就会<u>跨Socket申请内存</u>，进而造成跨Socket访问内存，造成实例的性能降低。

##### keys命令替代品

keys命令会扫描所有的键，可能导致Redis堵塞，所以有哪些可以替代keys的命令呢？

```c
scan cursor [MATCH pattern] [COUNT count]       #基于整个redis库进行扫描
sscan key cursor [MATCH pattern] [COUNT count]  #扫描指定的set类型的key
hscan key cursor [MATCH pattern] [COUNT count]  #扫描指定的hash类型的key
zscan key cursor [MATCH pattern] [COUNT count]  #扫描指定的zset类型的key
```

##### 如何找到bigkey

1.   慢查询日志

     >   *   **slowlog-log-slower-than**：这个参数表示，慢查询日志对执行时间大于多少微秒的命令进行记录。
     >   *   **slowlog-max-len**：这个参数表示，慢查询日志最多能记录多少条命令记录。慢查询日志的底层实现是一个具有预定大小的先进先出队列，一旦记录的命令数量超过了队列长度，最先记录的命令操作就会被删除。这个值默认是128。但是，如果慢查询命令较多的话，日志里就存不下了；如果这个值太大了，又会占用一定的内存空间。所以，一般建议设置为1000左右，这样既可以多记录些慢查询命令，方便排查，也可以避免内存开销。

2.   latency monitor监控工具





### 23.旁路缓存

[如何保证缓存一致性](./分布式&高并发\场景题.md)

本节介绍的是tomcat在访问数据时去访问Redis，缓存缺失时会访问mysql，然后更新缓存，具体怎么更新缓存呢？

Redis缓存的两种类型：**只读缓存和读写缓存**。只读缓存能加速读请求，而读写缓存可以同时加速读写请求。而且，读写缓存又有两种数据写回策略，可以让我们根据业务需求，在保证性能和保证数据可靠性之间进行选择。

##### 只读缓存

把修改**写到后端数据库**中，再把**缓存中的数据删除**。当下次访问这个数据时，会以后端数据库中的值为准，重新加载到缓存中。这样做的优点是，数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。<u>缺点是每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大</u>。



##### 读写缓存

同步直写和异步写回两种策略。

**同步直写**是指，写请求发给缓存的同时，也发给后端数据库进行处理，等到缓存和数据库都写完数据，才给客户端返回。提供了数据可靠性保证。

不过，同步直写会降低缓存的访问性能。这是因为缓存中处理写请求的速度是很快的，而数据库处理写请求的速度较慢。即使缓存很快地处理了写请求，也需要等待数据库处理完所有的写请求，才能给应用返回结果，这就增加了缓存的响应延迟。

而**异步写回策略**，则是优先考虑了响应延迟。此时，所有写请求都先在缓存中处理。等到这些增改的数据要被从缓存中淘汰出来时，缓存将它们写回后端数据库。这样一来，处理这些数据的操作是在缓存中进行的，很快就能完成。只不过，如果发生了掉电，而它们还没有被写回数据库，就会有丢失的风险了。

### 24.替换策略：缓存满了怎么办？

**缓存数据的淘汰机制**。简单来说，数据淘汰机制包括两步：第一，根据一定的策略，筛选出对应用访问来说“不重要”的数据；第二，将这些数据从缓存中删除，为新来的数据腾出空间，

##### Redis缓存有哪些淘汰策略？

Redis 4.0之前一共实现了6种内存淘汰策略，在4.0之后，又增加了2种策略。我们可以按照是否会进行数据淘汰把它们分成两类：

- 不进行数据淘汰的策略，只有**noeviction这一种**。
- 会进行淘汰的7种其他策略。

会进行淘汰的7种策略，我们可以再进一步根据淘汰候选数据集的范围把它们分成两类：

- <u>在设置了过期时间的数据中进行淘汰</u>，包括volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis 4.0后新增）四种。
- 在所有数据范围内进行淘汰，包括allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0后新增）三种。

对于allkeys-lru策略，由于维护双向链表和hash表过于占内存，所以redis对LRU算法作出了改进，Redis在决定淘汰的数据时，第一次会随机选出N个数据，把它们作为一个候选集合。接下来，Redis会比较这N个数据的lru字段，把lru字段值最小的数据从缓存中淘汰出去。

当需要再次淘汰数据时，Redis需要挑选数据进入候选集合。这儿的挑选标准是：**能进入候选集合的数据的lru字段值必须小于候选集合中最小的lru值**。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了maxmemory-samples，Redis就把候选数据集中lru字段值最小的数据淘汰出去。

##### 使用建议

- **优先使用allkeys-lru策略**。这样，可以充分利用LRU这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用的访问性能。如果你的业务数据中有明显的冷热数据区分，我建议你使用allkeys-lru策略。
- 如果业务应用中的数据访问频率相差不大，没有明显的冷热数据区分，建议使用allkeys-random策略，随机选择淘汰的数据就行。
- **如果你的业务中有置顶的需求**，比如置顶新闻、置顶视频，那么，可以使用volatile-lru策略，同时不给这些置顶数据设置过期时间。这样一来，这些需要置顶的数据一直不会被删除，而其他数据会在过期时根据LRU规则进行筛选。

##### 留言精选

如何保证数据库和缓存的一致性？只读缓存模式，读写缓存模式+同步直写策略（Cache Aside策略（只读缓存），Read/Write Throught策略（），Write Back(**读写缓存模式+异步写回策略**)）

##### 总结



### 25.解决缓存和数据库的数据不一致问题？

**4个方面：**缓存中的数据和数据库中的<u>不一致</u>；<u>缓存雪崩；缓存击穿和缓存穿透</u>。

**对于读写缓存：**有**同步直写策略**（同时写缓存和数据库）, **异步写回策略**(先写缓存，等到数据从缓存中淘汰时，再写回数据库，可能丢失数据)

**对于读缓存：**[看这里的](./分布式&高并发\场景题.md)

### 26-解决缓存雪崩、击穿、穿透？

缓存雪崩:1.大量key失效，导致请求都打到数据库中2.redis缓存实例宕机，可以**实现服务熔断或请求限流机制**，Redis缓存高可靠集群

缓存击穿：某个热点数据突然过期,导致大量请求打到数据库中。1.不设置过期时间

缓存穿透:访问的数据既不在Redis缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据,这是也没有缓存该请求就会一直打到数据库，导致数据库宕机。解决办法：1.布隆过滤器，2.查询不到的缓存，可以在redis中设置一个空值3.前端进行限流，针对ip，cookie等

<img src="assets/b5bd931239be18bef24b2ef36c70e9e1.jpg" alt="img" style="zoom:23%;" />

### 29-无锁的原子操作：应对并发访问？

Redis如何保证原子操作

1. Redis提供了INCR/DECR命令原子增减操作，这些操作都是单命令操作，可以保证
2. 如果需要多个操作的原子性，可以将这些操作写到lua脚本中，在通过Redis的**EVAL命令**来执行脚本,**在编写Lua脚本时，你要避免把不需要做并发控制的操作写入脚本中**。

### 30.Redis实现分布式锁？

##### SETNX和DEL命令组合来实现加锁和释放锁操作。

1.   发生异常，不会自动释放，导致资源一直占用；解决办法：**给锁变量设置一个过期时间**，超时释放
2.   如果客户端A执行了SETNX命令加锁后，假设客户端B执行了DEL命令释放锁，此时，客户端A的锁就被误释放了：解决办法：setnx设置一个客户端可以识别的标识。在释放时，判断标识是否符合当前客户端，

##### 基于多个Redis节点实现高可靠的分布式锁

Redis的开发者Antirez提出了分布式锁算法Redlock。<u>Redlock算法的基本思路</u>，是让客户端和多个独立的Redis实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个Redis实例发生故障，因为锁变量在其它实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失。

分为三个步骤：1.**客户端获取当前时间**2. **客户端按顺序依次向N个Redis实例执行加锁操作**3.判断是否加锁时间，是否超时，超时则释放

### 31. 事务机制：Redis能实现ACID属性吗？

事务：ACID四个特性

Redis使用MULTI和EXEC配合使用

##### Redis的事务机制能保证哪些属性？

###### 原子性保证：

*   命令入队时就报错，在exec执行时就会放弃事务执行，保证原子性；
*   命令入队时没报错，实际执行时报错，不保证原子性；
*   EXEC命令执行时实例故障，如果开启了AOF日志，可以保证原子性。

###### 一致性保证：

命令入队时就报错，会被放弃执行，可以保证一致性

命令入队时没报错，实际执行时报错，有错误的命令不会被执行，正确的命令可以正常执行，可以保证一致性。

EXEC命令执行时实例发生故障：1、**使用了RDB快照**，因为RDB快照不会在事务执行时执行，所以，事务命令操作的结果不会被保存到RDB快照中，使用RDB快照进行恢复时，数据库里的数据也是一致的。2.**使用了AOF日志**，而事务操作还没有被记录到AOF日志时，实例就发生了故障，那么，使用AOF日志恢复的数据库数据是一致的。如果只有部分操作被记录到了AOF日志，我们可以使用redis-check-aof清除事务中已经完成的操作，数据库恢复后也是一致的

###### 隔离性

事务执行又可以分成**命令入队**（EXEC命令执行前）和**命令实际执行**（EXEC命令执行后）两个阶段

1.  并发操作在EXEC命令前执行，此时，隔离性的保证要使用WATCH机制来实现，否则隔离性无法保证；
2.  并发操作在EXEC命令后执行，此时，隔离性可以保证。

WATCH机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用EXEC命令执行时，WATCH机制会先检查监控的键是否被其它客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证。

##### 持久性

如果Redis使用了RDB模式，那么，在一个事务执行后，而下一次的RDB快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的。

如果Redis采用了AOF模式，因为AOF模式的三种配置选项no、everysec和always都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证。

##### 总结

<img src="assets/9571308df0620214d7ccb2f2cc73a250.jpg" alt="img" style="zoom:37%;" />

Redis的事务机制可以保证一致性和隔离性，但是无法保证持久性，只有当事务中使用的命令语法有误时，**原子性得不到保证**，在其它情况下，事务都可以原子性执行。

在执行事务时，如果 Redis 实例发生故障，而 Redis 使用的 RDB 机制，事务的原子性还能否得到保证？

我觉得是可以保证原子性的。

如果一个事务只执行了一半，然后 Redis 实例故障宕机了，由于 RDB 不会在事务执行时执行，所以 RDB 文件中不会记录只执行了一部分的结果数据。之后用 RDB 恢复实例数据，恢复的还是事务之前的数据。但 RDB 本身是快照持久化，所以会存在数据丢失，丢失的是距离上一次 RDB 之间的所有更改操作。

关于 Redis 事务的使用，有几个细节我觉得有必要补充下，关于 Pipeline 和 WATCH 命令的使用。

1、在使用事务时，建议配合 Pipeline 使用。

a) 如果不使用 Pipeline，客户端是先发一个 MULTI 命令到服务端，客户端收到 OK，然后客户端再发送一个个操作命令，客户端依次收到 QUEUED，最后客户端发送 EXEC 执行整个事务（文章例子就是这样演示的），这样消息每次都是一来一回，效率比较低，而且在这多次操作之间，别的客户端可能就把原本准备修改的值给修改了，所以无法保证隔离性。

b) 而使用 Pipeline 是一次性把所有命令打包好全部发送到服务端，服务端全部处理完成后返回。这么做好的好处，一是减少了来回网络 IO 次数，提高操作性能。二是一次性发送所有命令到服务端，服务端在处理过程中，是不会被别的请求打断的（Redis单线程特性，此时别的请求进不来），这本身就保证了隔离性。我们平时使用的 Redis SDK 在使用开启事务时，一般都会默认开启 Pipeline 的，可以留意观察一下。

2、关于 WATCH 命令的使用场景。

a) 在上面 1-a 场景中，也就是使用了事务命令，但没有配合 Pipeline 使用，如果想要保证隔离性，需要使用 WATCH 命令保证，也就是文章中讲 WATCH 的例子。但如果是 1-b 场景，使用了 Pipeline 一次发送所有命令到服务端，那么就不需要使用 WATCH 了，因为服务端本身就保证了隔离性。

b) 如果事务 + Pipeline 就可以保证隔离性，那 WATCH 还有没有使用的必要？答案是有的。对于一个资源操作为读取、修改、写回这种场景，如果需要保证事物的原子性，此时就需要用到 WATCH 了。例如想要修改某个资源，但需要事先读取它的值，再基于这个值进行计算后写回，如果在这期间担心这个资源被其他客户端修改了，那么可以先 WATCH 这个资源，再读取、修改、写回，如果写回成功，说明其他客户端在这期间没有修改这个资源。如果其他客户端修改了这个资源，那么这个事务操作会返回失败，不会执行，从而保证了原子性。

### 32.Redis主从同步与故障切换

##### 主从数据不一致

由于读写分离导致的，在主库上修改，在从库上读取然后读取到旧值；

<u>解决办法：</u>1.保证网络良好2. 通过监控主从同步进度，来判断主从复制进度差值，大于某个阈值则停止在从库上读。

##### 读取过期数据

由于Redis的过期数据删除策略(**惰性删除策略和定期删除策略**),可能导致数据已经过期，但是Redis的过期策略并没有及时删除；

在3.2版本后，Redis做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值，这就避免了客户端读到过期数据。所以，**在应用主从集群时，尽量使用Redis 3.2及以上版本**。

数据过期命令：

<img src="assets/06e8cb2f1af320d450a29326a876f4e1.jpg" alt="img" style="zoom:60%;" />

所以当使用EXPIRE命令后，从库同步命令，那么就有可能将key的存活时间设置为当前时间后的ttl秒，导致主库和从库同一个数据过期时间不一样

所以在实际业务中：**在业务应用中使用EXPIREAT/PEXPIREAT命令，把数据的过期时间设置为具体的时间点，避免读到过期数据。**

##### 不合理配置项导致的服务挂掉

分别是**protected-mode和cluster-node-timeout。**

**protected-mode 配置项**

**protected-mode 配置项**配置项的作用是限定哨兵实例能否被其他服务器访问。当这个配置项设置为yes时，哨兵实例只能在部署的服务器本地进行访问。当设置为no时，其他服务器也可以访问这个哨兵实例。

正因为这样，如果protected-mode被设置为yes，而其余哨兵实例部署在其它服务器，那么，这些哨兵实例间就无法通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，最终Redis服务不可用。

所以，我们在应用主从集群时，要注意将protected-mode 配置项设置为no，并且将bind配置项设置为其它哨兵实例的IP地址。这样一来，只有在bind中设置了IP地址的哨兵，才可以访问当前实例，既保证了实例间能够通信进行主从切换，也保证了哨兵的安全性。

**cluster-node-timeout配置项**：**设置了Redis Cluster中实例响应心跳消息的超时时间**。如果设置过短加上网络延迟可能会有半数以上的实例心跳超时，从而可能导致整个集群挂掉

### 33.脑裂：一次奇怪的数据丢失

**脑裂**就是指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。

##### 为什么会发生数据丢失？

第一步：确认是不是数据同步出现了问题,**主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。**可以通过比对主从库上的复制进度差值来进行判断，也就是计算master_repl_offset和slave_repl_offset的差值

第二步：排查客户端的操作日志，发现脑裂现象.

第三步：发现是原主库假故障导致的脑裂

在切换过程中，既然客户端仍然和原主库通信，这就表明，**原主库并没有真的发生故障**（例如主库进程挂掉）。我们猜测，主库是由于某些原因无法处理请求，也没有响应哨兵的心跳，才被哨兵错误地判断为客观下线的。结果，在被判断下线之后，原主库又重新开始处理请求了，而此时，哨兵还没有完成主从切换，客户端仍然可以和原主库通信，客户端发送的写操作就会在原主库上写入数据了。为了验证原主库只是“假故障”，我们也查看了原主库所在服务器的资源使用监控记录。

的确，我们看到**原主库所在的机器有一段时间的CPU利用率突然特别高，这是我们在机器上部署的一个数据采集程序导致的**。因为这个程序基本把机器的CPU都用满了，导致Redis主库无法响应心跳了，在这个期间内，哨兵就把主库判断为客观下线，开始主从切换了。不过，这个数据采集程序很快恢复正常，CPU的使用率也降下来了。此时，原主库又开始正常服务请求了。

<img src="assets/1339e1bfe6d07da8477342ba5fyy9872.jpg" alt="img" style="zoom:23%;" />

##### 为什么脑裂会导致数据丢失？

redis的集群脑裂是指因为网络问题，导致redis master节点跟redis slave节点和sentinel集群**处于不同的网络分区**，此时因为sentinel集群无法感知到master的存在，所以**将slave节点提升为master节点**。此时存在两个不同的master节点，就像一个大脑分裂成了两个。
集群脑裂问题中，如果客户端还在基于原来的master节点继续写入数据，那么新的master节点将无法同步这些数据，**当网络问题解决之后**，<u>sentinel集群将原先的master节点降为slave节点，此时再从新的master中同步数据，将会造成大量的数据丢失</u>。

### 35. CodisVSRedisCluster

[Redis集群解决方案](./中间件\Redis\Redis集群方案.md)

### 36. 秒杀场景Redis作用都有哪些？





### 37.如何应对数据倾斜

切片集群根据Slot（逻辑槽）将数据分布在不同的机器上，但可能导致一个问题：<u>数据倾斜</u>

数据倾斜有两类。

*   **数据量倾斜**：在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多。
*   **数据访问倾斜**：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁。

导致数据倾斜的三个原因：1. 某个实例上保存了bigkey  2. Slot分配不均衡   3. Hash Tag

##### bigkey导致倾斜

所以我们需要在Redis中尽量避免bigkey问题，避免把过多的数据保存在同一个键值对中，如果bigkey正好是集合类型，我们还有一个方法，就是把bigkey拆分成很多个小的集合类型数据，分散保存在不同的实例上。

##### Slot分配不均衡导致倾斜

<u>查看分配好Slot：</u>如果是Redis Cluster，就用`CLUSTER SLOTS`命令；如果是Codis，就可以在`codis dashboard`上查看。

##### Hash Tag导致倾斜

Hash Tag是指加在键值对key中的一对花括号{}。这对括号会把key的一部分括起来，客户端在计算key的CRC16值时，只对Hash Tag花括号中的key内容进行计算。如果没用Hash Tag的话，客户端计算整个key的CRC16的值。

Hash Tag的潜在问题: 就是大量的数据可能被集中到一个实例上，导致数据倾斜，集群中的负载不均衡。

##### 解决办法

在这种情况下，我们可以采用**热点数据多副本**的方法来应对。

**对于只读数据：**可以把热点数据复制多份，在每一个数据副本的key中增加一个随机前缀，让它和其它副本数据不会被映射到同一个Slot中。这样一来，热点数据既有多个副本可以同时服务请求，同时，这些副本数据的key又不一样，会被映射到不同的Slot中。在给这些Slot分配实例时，我们也要注意把它们分配到不同的实例上，那么，热点数据的访问压力就被分散到不同的实例上了。

对于读写数据：要给实例本身增加资源了，例如使用配置更高的机器，来应对大量的访问压力。

### 38.通信开销：限制RedisCluster规模的关键因素

Redis官方给出了Redis Cluster的规模上限，就是一个集群运行1000个实例,为什么要限定集群规模呢？一个关键因素就是，**实例间的通信开销会随着实例规模增加而增大**，在集群超过一定规模时（比如800节点），集群吞吐量反而会下降。所以，集群的实际规模会受到限制。

Redis Cluster在运行时，每个实例上都会保存Slot和实例的对应关系（也就是Slot映射表），以及自身的状态信息。为了让集群中的每个实例都知道其它所有实例的状态信息，实例之间会按照一定的规则进行通信。这个规则就是**Gossip协议**。

**Gossip协议的工作原理** 1. 实例之间会按照一定的频率，从集群中随机挑选一些实例，把PING消息发出去，交换彼此的状态信息。PING消息中封装了发送消息的实例自身的状态信息、部分其它实例的状态信息，以及Slot映射表。2. 在接收到PING消息后，返回一个PONG消息。PONG消息包含的内容和PING消息一样。

Gossip协议进行通信时，通信开销受到**通信消息大小**和**通信频率**这两方面的影响，消息越大、频率越高，相应的通信开销也就越大。

##### Gossip消息大小

PING消息的消息体是由clusterMsgDataGossip结构体组成

```c
typedef struct {
    char nodename[CLUSTER_NAMELEN];  //40字节，实例名称
    uint32_t ping_sent; //4字节
    uint32_t pong_received; //4字节
    char ip[NET_IP_STR_LEN]; //46字节 实例IP
    uint16_t port;  //2字节
    uint16_t cport;  //2字节
    uint16_t flags;  //2字节
    uint32_t notused1; //4字节
} clusterMsgDataGossip;
```

一共104字节，对于一个包含了1000个实例的集群来说，每个实例发送一个PING消息时，会包含100个实例的状态信息，总的数据量是 10400字节，再加上发送实例自身的信息，一个Gossip消息大约是10KB，为了让Slot映射表能够在不同实例间传播，PING消息中还带有一个长度为 16,384 bit 的 Bitmap，这个Bitmap的每一位对应了一个Slot，如果某一位为1，就表示这个Slot属于当前实例。这个Bitmap大小换算成字节后，是2KB。我们把实例状态信息和Slot分配信息相加，就可以得到一个PING消息的大小了，**大约是12KB**。

PONG消息和PING消息的内容一样，所以，它的大小大约是12KB。每个实例发送了PING消息后，还会收到返回的PONG消息，两个消息加起来有24KB，当<u>我们正常请求只有几kb的时候，那么为了维护集群正常运行就占用用掉了大部分的带宽</u>。

##### 实例间通信频率

Redis Cluster的实例启动后，默认会每秒从本地的实例列表中随机选出5个实例，再从这5个实例中找出一个最久没有通信的实例，把PING消息发送给该实例。

这有可能会出现，**有些实例一直没有被发送PING消息，导致它们维护的集群状态已经过期了**。

为了避免这种情况，Redis Cluster的实例会按照每**100ms一次的频率**，扫描本地的实例列表，如果发现有实例最近一次接收 PONG消息的时间，已经大于配置项 cluster-node-timeout的一半了（cluster-node-timeout/2），就会立刻给该实例发送 PING消息，更新这个实例上的集群状态信息。

每秒PING消息发送数量 = 1 + 10 * 实例数（最近一次接收PONG消息的时间超出cluster-node-timeout/2）1是指单实例常规按照每1秒发送一个PING消息，10是指每1秒内实例会执行10次检查，每次检查后会给PONG消息超时的实例发送消息。

##### 如何降低实例间的通信开销？

1.   我们可以减小实例传输的消息大小（PING/PONG消息、Slot分配信息），但是，因为集群实例依赖PING、PONG消息和Slot分配信息，来维持集群状态的统一，一旦减小了传递的消息大小，就会导致实例间的通信信息减少，不利于集群维护，所以，我们不能采用这种方式。

2.   实例间发送消息的频率有两个。

*   每个实例每1秒发送一条PING消息。这个频率不算高，如果再降低该频率的话，集群中各实例的状态可能就没办法及时传播了。
*   每个实例每100毫秒会做一次检测，给PONG消息接收超过cluster-node-timeout/2的节点发送PING消息。实例按照每100毫秒进行检测的频率，是Redis实例默认的周期性检查任务的统一频率，我们一般不需要修改它。
*   cluster-node-timeout这个配置项可以修改（定义了集群实例被判断为故障的心跳超时时间，默认是15秒）**可以调大cluster-node-timeout值**，比如说调大到20秒或25秒。这样一来， PONG消息接收超时的情况就会有所缓解，单实例也不用频繁地每秒执行10次心跳发送操作了。

##### 总结

如果我们采用跟Codis保存Slot分配信息相类似的方法，把集群实例状态信息和Slot分配信息保存在第三方的存储系统上（例如Zookeeper），这种方法会对集群规模产生什么影响吗？

 Redis Cluster 每个实例需要保存集群完整的路由信息，每增加一个实例，都需要多一次与其他实例的通信开销，如果有 N 个实例，集群就要存储 N 份完整的路由信息。而如果像 Codis 那样，把 Slot 信息存储在第三方存储上，那么**无论集群实例有多少，这些信息在第三方存储上只会存储一份**，也就是说，集群内的通信开销，不会随着实例的增加而增长。当集群需要用到这些信息时，直接从第三方存储上获取即可。

Redis Cluster 把所有功能都集成在了 Redis 实例上，包括路由表的交换、实例健康检查、故障自动切换等等，这么做的好处是，**部署和使用非常简单**，只需要部署实例，然后让多个实例组成切片集群即可提供服务。<u>但缺点也很明显，每个实例负责的工作比较重，如果看源码实现，也不太容易理解，而且如果其中一个功能出现 bug，只能升级整个 Redis Server 来解决。</u>

而 Codis 把这些功能拆分成多个组件，每个组件负责的工作都非常纯粹，**codis-proxy 负责转发请求**，**codis-dashboard 负责路由表的分发、数据迁移控制，codis-server 负责数据存储和数据迁移，哨兵负责故障自动切换，codis-fe 负责提供友好的运维界面**，每个组件都可以单独升级，这些组件相互配合，完成整个集群的对外服务。但其<u>缺点是组件比较多，部署和维护比较复杂</u>。

在实际的业务场景下，我觉得应该尽量避免非常大的分片集群，太大的分片集群一方面存在通信开销大的问题，另一方面也会导致集群变得越来越难以维护。而且当集群出问题时，对业务的影响也比较集中。建议针对不同的业务线、业务模块，单独部署不同的分片集群

### 39.Redis6.0的新特性

Redis6.0中的关键新特性：面向网络处理的多IO线程、客户端缓存、细粒度的权限控制，以及RESP 3协议的使用。

##### 从单线程处理网络请求到多线程处理

之前的Redis一直是单线程架构，虽然数据删除、快照生成、AOF重写等命令可以fork子进程去处理，但是<u>从网络IO处理到实际的读写命令处理，都是由单个线程完成的</u>，随着硬件CPU性能的提升，Redis的性能瓶颈有时会出现在网络IO的处理上，也就是说，**单个主线程处理网络请求的速度跟不上底层网络硬件的速度**。

为了应对这个问题：

1.   用户态网络协议栈（例如DPDK）取代内核网络协议栈，让网络请求的处理不用在内核里执行，直接在用户态完成处理就行(需要处理很多问题，太复杂)
2.   采用**多个IO线程来处理网络请求**，提高网络请求处理的并行度。Redis 6.0就是采用的这种方法。Redis的多IO线程只是用来处理网络请求的，对于读写命令，Redis仍然使用单线程来处理。因为，Redis处理请求时，网络处理经常是瓶颈，通过多个IO线程并行处理网络操作，可以提升实例的整体处理性能。而继续使用单线程执行命令操作，就不用为了保证Lua脚本、事务的原子性，额外开发多线程互斥机制。

主要实现过程：

1.   阶段一：服务端和客户端建立Socket连接，并分配处理线程
2.   阶段二：IO线程读取并解析请求
3.   阶段三：主线程执行请求操作
4.   阶段四：IO线程回写Socket和主线程清空全局队列

<img src="assets/5817b7e2085e7c00e63534a07c4182cd.jpg" alt="img" style="zoom:20%;" />

如何使用：

在Redis 6.0中，多线程机制默认是关闭的，如果需要使用多线程功能，需要在redis.conf中完成两个设置。

1.   设置io-thread-do-reads配置项为yes，表示启用多线程。
2.   设置线程个数。一般来说，**线程个数要小于Redis实例所在机器的CPU核个数**

##### 实现服务端协助的客户端缓存

Redis 6.0新增了一个重要的特性，就是实现了服务端协助的客户端缓存功能，也称为跟踪（Tracking）功能。但是存在的问题是：如何保证客户端缓存和服务器端数据一致性？6.0实现的Tracking功能实现了两种模式，来解决这个问题：

1.   **第一种模式是普通模式**。服务端会给客户端发送invalidate消息，通知客户端缓存失效了。
2.   **第二种模式是广播模式**。服务端会给客户端广播所有key的失效情况，不过，这样做了之后，如果key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。

普通模式和广播模式，需要客户端使用RESP 3协议，RESP 3协议是6.0新启用的通信协议；

对于使用RESP 2协议的客户端来说，就需要使用另一种模式，也就是<u>重定向模式（redirect）</u>。在重定向模式下，想要获得失效消息通知的客户端，就需要执行订阅命令SUBSCRIBE，专门订阅用于发送失效消息的频道_redis_:invalidate。同时，再使用另外一个客户端，执行CLIENT TRACKING命令，设置服务端将失效消息转发给使用RESP 2协议的客户端。

##### 从简单的基于密码访问到细粒度的权限控制

在Redis 6.0 版本之前，要想实现实例的安全访问，只能通过设置密码来控制；对于一些高风险的命令（例如KEYS、FLUSHDB、FLUSHALL等），只能通过rename-command来重新命名这些命令，避免客户端直接调用。

提出了两个办法：

1.   **6.0版本支持创建不同用户来使用Redis**。在6.0版本前，所有客户端可以使用同一个密码进行登录使用，但是没有用户的概念，而在6.0中，我们可以使用ACL SETUSER命令创建用户
2.   6.0版本还支持以用户为粒度设置命令操作的访问权限，可以通过ACL SETUSER来设置加减命令。

##### 启用RESP 3协议

在RESP 2中，客户端和服务器端的通信内容都是以字节数组形式进行编码的，客户端需要根据操作的命令或是数据类型自行对传输的数据进行解码，增加了客户端开发复杂度。

而RESP 3直接支持多种数据类型的区分编码，包括空值、浮点数、布尔值、有序的字典集合、无序的集合等。RESP 3协议还可以支持客户端以普通模式和广播模式实现客户端缓存。

### 40. Redis基于NVM内存的实践

DRAM, SRAM，NVM;

Redis发展的下一步，就可以基于NVM内存来实现大容量实例，或者是实现快速持久化数据和恢复,因为NVM器件具有<u>容量大、性能快、能持久化保存数据</u>的特性；

##### NVM内存的特性与使用模式

1.   **最大的优势是可以直接持久化保存数据**，掉电也没问题，但是目前的DRAM不行，掉电数据直接丢失
2.   **NVM内存的访问速度接近DRAM的速度**
3.   **NVM内存的容量很大**，单根NVM内存条就能达到128GB的容量，最大可以达到512GB，而单根DRAM内存条通常是16GB或32GB。所以，我们可以很轻松地用NVM内存构建TB级别的内存。

Intel在2019年4月份时推出的Optane AEP内存条，AEP内存给软件提供了两种使用模式，分别对应着使用了NVM的容量大和持久化保存数据两个特性

1.   Memory模式把NVM内存作为大容量内存来使用的，也就是说，只使用NVM容量大和性能高的特性，没有启用数据持久化的功能。
2.   App Direct模式启用了NVM持久化数据的功能

### 41.客户端与服务器交换命令和数据

如果要对Redis客户端进行二次开发（比如增加新的命令），我们就需要了解**请求和响应涉及的命令、数据在客户端和服务器之间传输时**，是如何编码的。否则，我们在客户端新增的命令就无法被服务器端识别和处理。

Redis使用RESP（REdis Serialization Protocol）协议定义了客户端和服务器端交互的命令、数据的编码格式。在Redis 2.0版本中，RESP协议正式成为客户端和服务器端的标准通信协议。从Redis 2.0 到Redis 5.0，RESP协议都称为RESP 2协议，从Redis 6.0开始，Redis就采用RESP 3协议

##### 客户端和服务器端交互的内容有哪些？

*   在客户端请求中，客户端会给Redis发送命令，以及要写入的键和值；
*   而在服务器端响应中，Redis实例会返回读取的值、OK标识、成功写入的元素个数、错误信息，以及命令（例如Redis Cluster中的MOVE命令）。

##### RESP 2的编码格式规范

1.  为了对不同类型的交互内容进行编码，<u>RESP 2协议实现了5种编码格式类型</u>。为了区分这5种编码类型，使用一个专门的字符，作为每种编码类型的开头字符。
2.  RESP 2进行编码时，会按照单个命令或单个数据的粒度进行编码，并在每个编码结果后面增加一个换行符“\r\n”（有时也表示成CRLF），表示一次编码结束。

1.   简单字符串类型（RESP Simple Strings）例如`+OK\r\n`;
2.   长字符串类型（RESP Bulk String）RESP 2就用这种类型对交互内容中的键或值进行编码，并且使用“`$`”字符作为开头字符，`$`字符后面会紧跟着一个数字，这个数字表示字符串的实际长度,例如：`$9 testvalue\r\n`
3.   整数类型（RESP Integer）整数类型使用“`:`”字符作为开头字符，可以用于对服务器端返回的整数回复进行编码`:3\r\n`
4.   错误类型（RESP Errors）是一个字符串，包括了错误类型和具体的错误信息。Redis服务器端报错响应就是用这种类型进行编码的。<u>RESP 2使用“`-`”字符作为它的开头字符。</u>`-ERR unknown command PUT, with args beginning with: testkey,testvalue`
5.   数组编码类型(RESP Arrays) 客户端在发送请求操作时，一般会同时包括命令和要操作的数据。而数组类型包含了多个元素，所以，就适合用来对发送的命令和数据进行编码。为了和其他类型区分，<u>RESP 2使用“`*`”字符作为开头字符</u>

##### RESP 2的不足和RESP 3的改进

一方面，在值的基本数据类型方面，RESP 2只能区分字符串和整数，对于其他的数据类型，客户端使用RESP 2协议时，就需要进行额外的转换操作。例如，当一个浮点数用字符串表示时，客户端需要将字符串中的值和实际数字值比较，判断是否为数字值，然后再将字符串转换成实际的浮点数。

另一方面，RESP 2用数组类别编码表示所有的集合类型，但是，Redis的集合类型包括了List、Hash、Set和Sorted Set。当客户端接收到数组类型编码的结果时，还需要根据调用的命令操作接口，来判断返回的数组究竟是哪一种集合类型。

例如：Hash类型的键是testhash和Sorted Set类型的键是testzset命令返回的结果可能一样：

```bash
127.0.0.1:6379>HGETALL testhash
1) "a"
2) "1"
3) "b"
4) "2"
5) "c"
6) "3"
127.0.0.1:6379>ZRANGE testzset 0 3 withscores
1) "a"
2) "1"
3) "b"
4) "2"
5) "c"
6) "3"
```

所以需要根据发送的命令操作HGETALL和ZRANGE，来把这两个编码的数组结果转换成相应的Hash集合和有序集合，增加了客户端额外的开销

**所以从Redis 6.0版本开始**，RESP 3协议增加了对多种数据类型的支持，包括空值、浮点数、布尔值、有序的字典集合、无序的集合等。RESP 3也是通过不同的开头字符来区分不同的数据类型，例如，当开头第一个字符是“`,`”，就表示接下来的编码结果是浮点数

### 42.Redis有哪些好用的运维工具？

##### INFO命令

可以带一个参数section，如下图所示

<img src="assets/8fb2ef487fd9b7073fd062d480b220a8.jpg" alt="img" style="zoom:27%;" />

**无论你是运行单实例或是集群，我建议你重点关注一下stat、commandstat、cpu和memory这四个参数的返回结果**，这里面包含了命令的执行情况（比如命令的执行次数和执行时间、命令使用的CPU资源），内存资源的使用情况（比如内存已使用量、内存碎片率），CPU资源使用情况等，这可以帮助我们判断实例的运行状态和资源消耗情况。

不过，INFO命令只是提供了文本形式的监控结果，并没有可视化，所以，在实际应用中，我们还可以使用一些第三方开源工具，将INFO命令的返回结果可**可视化监控时我们最好重点关注以下指标：**

1、客户端相关：当前连接数、总连接数、输入缓冲大小、OPS

2、CPU相关：主进程 CPU 使用率、子进程 CPU 使用率

3、内存相关：当前内存、峰值内存、内存碎片率

4、网络相关：输入、输出网络流量

5、持久化相关：最后一次 RDB 时间、RDB fork 耗时、最后一次 AOF rewrite 时间、AOF rewrite 耗时

6、key 相关：过期 key 数量、淘汰 key 数量、key 命中率

7、复制相关：主从节点复制偏移量、主库复制缓冲区

##### 面向Prometheus的Redis-exporter监控

[Prometheus](https://prometheus.io/)是一套开源的系统监控报警框架。它的核心功能是从被监控系统中拉取监控数据，结合[Grafana](https://grafana.com/)工具，进行可视化展示。而且，监控数据可以保存到时序数据库中，以便运维人员进行历史查询。同时，Prometheus会检测系统的监控指标是否超过了预设的阈值，一旦超过阈值，Prometheus就会触发报警。

Prometheus正好提供了插件功能来实现对一个系统的监控，我们把插件**称为exporter**，用来监控Redis的，它将INFO命令监控到的运行状态和各种统计信息提供给Prometheus，从而进行可视化展示和报警设置

##### 数据迁移工具Redis-shake

Redis-shake的基本运行原理，是先启动Redis-shake进程，这个进程模拟了一个Redis实例。然后，Redis-shake进程和数据迁出的源实例进行数据的全量同步。

这个过程和Redis主从实例的全量同步是类似的。
