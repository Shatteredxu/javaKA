## Linux网络报接收过程

-------------------------------------

### **Linux网络收包总览**

整个协议栈被分成了物理层、链路层、网络层，传输层和应用层。物理层对应的是网卡和网线，应用层对应的是我们常见的Nginx，FTP等等各种应用。Linux实现的是<u>链路层（网卡驱动）、网络层（内核协议）和传输层（内核协议）</u>这三层。

<img src="assets/640" alt="图片" style="zoom:50%;" />

在Linux的源代码中，网络设备驱动对应的逻辑位于`driver/net/ethernet`, 其中intel系列网卡的驱动在`driver/net/ethernet/intel`目录下。协议栈模块代码位于`kernel`和`net`目录。

内核和网络设备驱动是通过**中断的方式**来处理的。当设备上有数据到达的时候，会给CPU的相关引脚上触发一个电压变化，以通知CPU来处理数据。对于网络模块来说，由于处理过程比较复杂和耗时，如果在中断函数中完成所有的处理，将会导致中断处理函数（优先级过高）将过度占据CPU，将导致CPU无法响应其它设备，例如鼠标和键盘的消息。因此Linux中断处理函数是分上半部和下半部的。<u>上半部是只进行最简单的工作，快速处理然后释放CPU</u>，接着CPU就可以允许其它中断进来。剩下将绝大部分的工作都放到下半部中，可以慢慢从容处理。<u>2.4以后的内核版本采用的下半部实现方式是软中断</u>，由ksoftirqd内核线程全权处理。和硬中断不同的是，<u>硬中断是通过给CPU物理引脚施加电压变化，而软中断是通过给内存中的一个变量的二进制值以通知软中断处理程序</u>。

<img src="assets/640" alt="图片" style="zoom:50%;" />

1. 当网卡上收到数据以后，Linux中第一个工作的模块是网络驱动。**网络驱动会以DMA的方式把网卡上收到的帧写到内存里**。再向CPU发起一个**中断**，以通知CPU有数据到达。

2. 第二，当CPU收到中断请求后，会去调用网络驱动注册的中断处理函数。网卡的中断处理函数并不做过多工作，发出软中断请求，然后尽快释放CPU。
3. ksoftirqd检测到有软中断请求到达，调用poll开始轮询收包，收到后交由各级协议栈处理。对于UDP包来说，会被放到用户socket的接收队列中。

### Linux启动

接收网卡数据包之前，要做很多的准备工作。1. 提前创建好ksoftirqd内核线程，2. 注册好各个协议对应的处理函数，3. 网络设备子系统要提前初始化好，4. 网卡要启动好。

##### 创建ksoftirqd内核线程

创建内核线程，然后不断轮询判断有没有软中断需要处理，

##### 网络子系统初始化

初始化数据结构，为每个软中断注册处理函数

<img src="assets/640" alt="图片" style="zoom:50%;" />

##### 协议栈注册

内核实现了网络层的ip协议，也实现了传输层的tcp协议和udp协议。这些协议对应的实现函数分别是ip_rcv(),tcp_v4_rcv()和udp_rcv()。和我们平时写代码的方式不一样的是，内核是通过注册的方式来实现的。

初始化模块：`fs_initcall`调用`inet_init`后开始网络协议栈注册；

调用对应的协议注册函数初始化

<img src="assets/640" alt="图片" style="zoom:60%;" />

##### 网卡驱动初始化

每一个驱动程序（不仅仅只是网卡驱动）会使用 module_init 向内核注册一个初始化函数，当驱动被加载时，内核会调用这个函数。比如igb网卡驱动的代码位于`drivers/net/ethernet/intel/igb/igb_main.c`

<img src="assets/640" alt="图片" style="zoom:67%;" />

##### 启动网卡

启动网卡，分配ring Buffer内存，注册中断处理函数，打开硬中断，等待包。

<img src="assets/640" alt="图片" style="zoom:67%;" />

### **迎接数据的到来**

##### 硬中断处理

首先当数据帧从网线到达网卡上的时候，第一站是网卡的接收队列。网卡在分配给自己的RingBuffer中寻找可用的内存位置，找到后DMA引擎会把数据DMA到网卡之前关联的内存里，这个时候CPU都是无感的。当DMA操作完成以后，网卡会像CPU发起一个硬中断，通知CPU有数据到达。

<img src="assets/640" alt="图片" style="zoom:67%;" />

当RingBuffer满的时候，新来的数据包将给丢弃。ifconfig查看网卡的时候，可以里面有个overruns，表示因为环形队列满被丢弃的包。如果发现有丢包，可能需要通过ethtool命令来加大环形队列的长度。

硬中断处理过程非常短。只是<u>记录了一个寄存器，修改了一下下CPU的poll_list，然后发出个软中断</u>。

##### ksoftirqd内核线程处理软中断

硬中断中设置软中断标记，和ksoftirq的判断是否有软中断到达，都是基于smp_processor_id()的。这意味着只要硬中断在哪个CPU上被响应，那么软中断也是在这个CPU上处理的。所以说，如果你发现你的Linux软中断CPU消耗都集中在一个核上的话，做法是要把**<u>调整硬中断的CPU亲和性，来将硬中断打散到不同的CPU核上去。</u>**

##### 网络协议栈处理

先到IP处理函数，再到TCP或者UDP的处理函数，`__udp4_lib_lookup_skb`是根据skb来寻找对应的socket，当找到以后将数据包放到socket的缓存队列里。如果没有找到，则发送一个目标不可达的icmp包。sock_owned_by_user判断的是用户是不是正在这个socker上进行系统调用（socket被占用），如果没有，那就可以直接放到socket的接收队列中。如果有，那就通过`sk_add_backlog`把数据包添加到backlog队列。当用户释放的socket的时候，内核会检查backlog队列，如果有数据再移动到接收队列中。

### **recvfrom系统调用**

经历了上面的过程，就已经把数据包放到socket的接收队列中了，我们再回头看用户进程调用`recvfrom`后是发生了什么。我们在代码里调用的`recvfrom`是一个glibc的库函数，该函数在执行后会将用户进行陷入到内核态，进入到Linux实现的系统调用`sys_recvfrom`

`socket`数据结构中的`const struct proto_ops`对应的是协议的方法集合。每个协议都会实现不同的方法集，对于IPv4 Internet协议族来说,每种协议都有对应的处理方法；`socket`数据结构中的另一个数据结构`struct sock *sk`是一个非常大，非常重要的子结构体；

<img src="assets/640" alt="图片" style="zoom:80%;" />

```c++
//调用__skb_recv_datagram
struct sk_buff *__skb_recv_datagram(struct sock *sk, unsigned int flags,int *peeked, int *off, int *err){
    ......
    do {
        struct sk_buff_head *queue = &sk->sk_receive_queue;//取到queue
        skb_queue_walk(queue, skb) {
            ......
        }

        /* User doesn't want to wait */
        error = -EAGAIN;
        if (!timeo)
            goto no_packet;
    } while (!wait_for_more_packets(sk, err, &timeo, last));//一直进行循环，如果没有数据则等待，进入睡眠状态。
}
```



上面我们看到了所谓的读取过程，就是访问`sk->sk_receive_queue`。如果没有数据，且用户也允许等待，则将调用wait_for_more_packets()执行等待操作，它加入会让用户进程进入睡眠状态。

**总结**

网络模块是Linux内核中最复杂的模块了，看起来一个简简单单的收包过程就涉及到许多内核组件之间的交互，如网卡驱动、协议栈，内核ksoftirqd线程等。看起来很复杂，本文想通过图示的方式，尽量以容易理解的方式来将内核收包过程讲清楚。现在让我们再串一串整个收包过程。

当用户执行完`recvfrom`调用后，用户进程就通过系统调用进行到内核态工作了。如果接收队列没有数据，进程就进入睡眠状态被操作系统挂起。这块相对比较简单，剩下大部分的戏份都是由Linux内核其它模块来表演了。

首先在开始收包之前，Linux要做许多的**准备工作：**

- 创建ksoftirqd线程，为它设置好它自己的线程函数，后面指望着它来处理软中断呢
- 协议栈注册，linux要实现许多协议，比如arp，icmp，ip，udp，tcp，每一个协议都会将自己的处理函数注册一下，方便包来了迅速找到对应的处理函数
- 网卡驱动初始化，每个驱动都有一个初始化函数，内核会让驱动也初始化一下。在这个初始化过程中，把自己的DMA准备好，把NAPI的poll函数地址告诉内核
- 启动网卡，分配RX，TX队列，注册中断对应的处理函数

以上是内核准备收包之前的重要工作，当上面都ready之后，就可以打开硬中断，**等待数据包的到来了。**

当数据到来了以后，第一个迎接它的是**网卡**：

- 网卡将数据帧DMA到内存的RingBuffer中，然后向CPU发起中断通知
- CPU响应中断请求，调用网卡启动时注册的中断处理函数
- 中断处理函数几乎没干啥，就发起了软中断请求
- 内核线程ksoftirqd线程发现有软中断请求到来，先关闭硬中断
- ksoftirqd线程开始调用驱动的poll函数收包
- poll函数将收到的包送到协议栈注册的ip_rcv函数中
- ip_rcv函数再讲包送到udp_rcv函数中（对于tcp包就送到tcp_rcv）